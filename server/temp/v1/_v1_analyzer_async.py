#!/usr/bin/env python3
"""
Async Token Analyzer - –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∏–π –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä —Ç–æ–∫–µ–Ω—ñ–≤ –∑ SQLite
–ê–Ω–∞–ª—ñ–∑—É—î —Ç–æ–∫–µ–Ω–∏ –∫–æ–∂–Ω—ñ 3 —Å–µ–∫—É–Ω–¥–∏, 3 —ñ—Ç–µ—Ä–∞—Ü—ñ—ó –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
"""

import asyncio
import aiohttp
import aiosqlite
import json
import time
import random
from datetime import datetime
from typing import Dict, Any, Optional, List, Set
import os

# –ö–æ–Ω—Ñ—ñ–≥ —Ä–µ—Ç—Ä–∞—ó–≤
RETRY_COUNT = 3
RETRY_BACKOFF_BASE = 0.4

class AsyncTokenAnalyzer:
    def __init__(self, debug: bool = False):
        self.solana_rpc_url = "https://api.mainnet-beta.solana.com"
        self.session: Optional[aiohttp.ClientSession] = None
        self.debug = debug
        self.db_path = "db/tokens.db"
        self.conn: Optional[aiosqlite.Connection] = None
        self.db_lock = asyncio.Lock()
        
        # –ß–µ—Ä–≥–∞ –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–∫–µ–Ω—ñ–≤
        self.analysis_queue: Dict[str, Dict[str, Any]] = {}  # token_id -> {iterations_left, last_analysis}
        self.analysis_lock = asyncio.Lock()
        
        # Rate limiting –¥–ª—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞
        self.rate_limit_delay = 1.0  # 1 —Å–µ–∫—É–Ω–¥–∞ –º—ñ–∂ –∞–Ω–∞–ª—ñ–∑–∞–º–∏
        self.last_analysis_time = 0
        
    def _debug_print(self, *args):
        if self.debug:
            print("[ANALYZER DEBUG]", *args)
    
    async def respect_rate_limit(self):
        """Ensure we don't exceed rate limits for analysis"""
        current_time = time.time()
        time_since_last_analysis = current_time - self.last_analysis_time
        
        if time_since_last_analysis < self.rate_limit_delay:
            sleep_time = self.rate_limit_delay - time_since_last_analysis
            if self.debug:
                print(f"‚è≥ Analysis rate limiting: waiting {sleep_time:.1f}s")
            await asyncio.sleep(sleep_time)
        
        self.last_analysis_time = time.time()
    
    async def batch_analyze_tokens(self, token_addresses: List[str]) -> Dict[str, Any]:
        """Batch analyze multiple tokens using Jupiter API (up to 100 tokens per request)"""
        try:
            await self.ensure_session()
            
            if not token_addresses:
                return {}
            
            # Jupiter API supports up to 100 mint addresses in one query
            batch_size = 100
            results = {}
            
            for i in range(0, len(token_addresses), batch_size):
                batch = token_addresses[i:i + batch_size]
                
                # Create comma-separated query string
                query_string = ",".join(batch)
                url = f"https://lite-api.jup.ag/tokens/v2/search?query={query_string}"
                
                if self.debug:
                    print(f"üîç Batch analyzing {len(batch)} tokens...")
                
                # Rate limiting before request
                await self.respect_rate_limit()
                
                async with self.session.get(url, timeout=30) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # Process each token in the response
                        for token_data in data:
                            token_id = token_data.get('id', '')
                            if token_id:
                                results[token_id] = {
                                    'jupiter_data': token_data,
                                    'timestamp': datetime.now().isoformat()
                                }
                        
                        if self.debug:
                            print(f"‚úÖ Batch analysis complete: {len(data)} tokens processed")
                    else:
                        error_text = await response.text()
                        if self.debug:
                            print(f"‚ùå Batch analysis failed: {response.status} - {error_text}")
                        return {}
            
            return results
            
        except Exception as e:
            if self.debug:
                print(f"‚ùå Batch analysis error: {e}")
            return {}

    async def ensure_connection(self):
        """Ensure database connection is established"""
        if self.conn is None:
            self.conn = await aiosqlite.connect(self.db_path)
            
            # SQLite PRAGMA –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            await self.conn.execute("PRAGMA journal_mode=WAL;")
            await self.conn.execute("PRAGMA synchronous=NORMAL;")
            await self.conn.execute("PRAGMA cache_size=-64000;")
            await self.conn.execute("PRAGMA temp_store=MEMORY;")
            await self.conn.execute("PRAGMA foreign_keys=ON;")
            
            await self.init_db()

    async def close(self):
        """Close all resources"""
        if self.session:
            await self.session.close()
        if self.conn:
            await self.conn.close()
            self.conn = None

    async def init_db(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞–±–ª–∏—Ü—å –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–∫–µ–Ω—ñ–≤ –∑–≥—ñ–¥–Ω–æ –∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—î—é"""
        async with self.db_lock:
            # DexScreener —Ç–∞–±–ª–∏—Ü—ñ
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_pairs (
                    token_id INTEGER PRIMARY KEY,
                    chain_id TEXT,
                    dex_id TEXT,
                    url TEXT,
                    pair_address TEXT,
                    price_native TEXT,
                    price_usd TEXT,
                    fdv NUMERIC,
                    market_cap NUMERIC,
                    pair_created_at TIMESTAMP,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_base_token (
                    token_id INTEGER PRIMARY KEY,
                    address TEXT,
                    name TEXT,
                    symbol TEXT,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_quote_token (
                    token_id INTEGER PRIMARY KEY,
                    address TEXT,
                    name TEXT,
                    symbol TEXT,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_txns (
                    token_id INTEGER PRIMARY KEY,
                    m5_buys INTEGER,
                    m5_sells INTEGER,
                    h1_buys INTEGER,
                    h1_sells INTEGER,
                    h6_buys INTEGER,
                    h6_sells INTEGER,
                    h24_buys INTEGER,
                    h24_sells INTEGER,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_volume (
                    token_id INTEGER PRIMARY KEY,
                    h24 NUMERIC,
                    h6 NUMERIC,
                    h1 NUMERIC,
                    m5 NUMERIC,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_price_change (
                    token_id INTEGER PRIMARY KEY,
                    m5 NUMERIC,
                    h1 NUMERIC,
                    h6 NUMERIC,
                    h24 NUMERIC,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS dexscreener_liquidity (
                    token_id INTEGER PRIMARY KEY,
                    usd NUMERIC,
                    base NUMERIC,
                    quote NUMERIC,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            # Solana RPC —Ç–∞–±–ª–∏—Ü—ñ
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS solana_token_supply (
                    token_id INTEGER PRIMARY KEY,
                    amount TEXT,
                    decimals INTEGER,
                    ui_amount NUMERIC,
                    ui_amount_string TEXT,
                    slot INTEGER,
                    api_version TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS solana_token_metadata (
                    token_id INTEGER PRIMARY KEY,
                    decimals INTEGER,
                    freeze_authority TEXT,
                    is_initialized BOOLEAN,
                    mint_authority TEXT,
                    supply TEXT,
                    program TEXT,
                    space INTEGER,
                    executable BOOLEAN,
                    lamports INTEGER,
                    owner TEXT,
                    rent_epoch TEXT,
                    slot INTEGER,
                    api_version TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS solana_recent_signatures (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    token_id INTEGER,
                    block_time INTEGER,
                    confirmation_status TEXT,
                    err TEXT,
                    memo TEXT,
                    signature TEXT,
                    slot INTEGER,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS solana_dev_activity (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    token_id INTEGER,
                    block_time INTEGER,
                    confirmation_status TEXT,
                    err TEXT,
                    memo TEXT,
                    signature TEXT,
                    slot INTEGER,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS solana_largest_accounts (
                    token_id INTEGER PRIMARY KEY,
                    error_message TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (token_id) REFERENCES token_ids(id)
                )
            """)
            
            # –Ü–Ω–¥–µ–∫—Å–∏ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            await self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_dexscreener_pairs_timestamp 
                ON dexscreener_pairs(timestamp)
            """)
            
            await self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_solana_supply_timestamp 
                ON solana_token_supply(timestamp)
            """)
            
            await self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_solana_signatures_timestamp 
                ON solana_recent_signatures(timestamp)
            """)
            
            await self.conn.commit()

    async def ensure_session(self):
        """Ensure HTTP session is initialized"""
        if self.session is None:
            self.session = aiohttp.ClientSession()

    async def add_tokens_to_analysis(self, token_ids: List[str]):
        """–î–æ–¥–∞—Ç–∏ —Ç–æ–∫–µ–Ω–∏ –¥–æ —á–µ—Ä–≥–∏ –∞–Ω–∞–ª—ñ–∑—É"""
        async with self.analysis_lock:
            added_count = 0
            for token_id in token_ids:
                if token_id not in self.analysis_queue:
                    self.analysis_queue[token_id] = {
                        'iterations_left': 3,  # 3 —ñ—Ç–µ—Ä–∞—Ü—ñ—ó –∞–Ω–∞–ª—ñ–∑—É
                        'last_analysis': None
                    }
                    added_count += 1
                    self._debug_print(f"Added {token_id} to analysis queue")
            
            self._debug_print(f"üìä Added {added_count} new tokens to analysis queue. Total queue size: {len(self.analysis_queue)}")

    async def analyze_token(self, token_address: str, iteration: int = 1) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑ –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"""
        start_time = time.time()

        try:
            # Rate limiting –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª—ñ–∑–æ–º
            await self.respect_rate_limit()
            
            await self.ensure_session()
            
            # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –∑ —Ä—ñ–∑–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª
            jupiter_data = await self._get_jupiter_data(token_address)
            dexscreener_data = await self._get_dexscreener_data(token_address)
            solana_rpc_data = await self._get_solana_rpc_data(token_address)
            holders_data = await self._get_token_holders(token_address)

            # Honeypot check
            honeypot_check = await self._honeypot_with_fallback(token_address, dexscreener_data, solana_rpc_data)

            # Dev address detection
            dev_address = self._extract_dev_from_jupiter(jupiter_data)
            dev_activity = await self._get_dev_activity(dev_address) if dev_address else None

            # LP owner
            pair_address = self._extract_pair_from_dexscreener(dexscreener_data)
            lp_owner = await self._get_lp_owner(pair_address) if pair_address else None

            analysis_time = time.time() - start_time

            result = {
                "token_address": token_address,
                "timestamp": datetime.now().isoformat(),
                "analysis_time": f"{analysis_time:.2f}s",
                "iteration": iteration,
                "raw_data": {
                    "jupiter": jupiter_data,
                    "dexscreener": dexscreener_data,
                    "solana_rpc": {
                        **solana_rpc_data,
                        "largest_accounts": holders_data,
                        "dev_activity": dev_activity
                    }
                },
                "security": {
                    "honeypot_check": honeypot_check,
                    "lp_owner": lp_owner,
                    "dev_address": dev_address
                }
            }

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–Ω–∞–ª—ñ–∑ –≤ SQLite
            await self.save_analysis(result)

            return result

        except Exception as e:
            self._debug_print(f"Error analyzing token {token_address}: {str(e)}")
            return {
                "token_address": token_address,
                "timestamp": datetime.now().isoformat(),
                "analysis_time": "0.00s",
                "iteration": iteration,
                "error": str(e)
            }

    async def save_analysis(self, analysis: Dict[str, Any]) -> bool:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É –≤ –Ω–æ–≤—ñ —Ç–∞–±–ª–∏—Ü—ñ –∑–≥—ñ–¥–Ω–æ –∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—î—é"""
        try:
            await self.ensure_connection()
            
            token_address = analysis['token_address']
            self._debug_print(f"üíæ SAVING ANALYSIS for {token_address}")
            
            # –û—Ç—Ä–∏–º—É—î–º–æ token_id –∑ token_ids —Ç–∞–±–ª–∏—Ü—ñ
            token_id = await self._get_token_id_by_address(token_address)
            if not token_id:
                self._debug_print(f"‚ùå Token {token_address} not found in token_ids table")
                return False
            
            async with self.db_lock:
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ DexScreener –¥–∞–Ω—ñ
                await self._save_dexscreener_data(token_id, analysis['raw_data']['dexscreener'])
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ Solana RPC –¥–∞–Ω—ñ
                await self._save_solana_rpc_data(token_id, analysis['raw_data']['solana_rpc'])
                
                # –û–Ω–æ–≤–ª—é—î–º–æ token_pair –≤ token_ids —è–∫—â–æ –∑–Ω–∞–π—à–ª–∏ –ø–∞—Ä—É
                pair_address = self._extract_pair_from_dexscreener(analysis['raw_data']['dexscreener'])
                if pair_address:
                    await self.conn.execute("""
                        UPDATE token_ids 
                        SET token_pair = ? 
                        WHERE id = ?
                    """, (pair_address, token_id))
                    self._debug_print(f"‚úÖ Updated token_pair for {token_address}: {pair_address}")
                
                # –û–Ω–æ–≤–ª—é—î–º–æ –æ—Å–Ω–æ–≤–Ω—ñ –¥–∞–Ω—ñ —Ç–æ–∫–µ–Ω–∞ –∑ DexScreener
                await self._update_token_data_from_dexscreener(token_id, analysis['raw_data']['dexscreener'])
                
                await self.conn.commit()
                self._debug_print(f"‚úÖ Analysis saved successfully for {token_address}")
                return True
                
        except Exception as e:
            self._debug_print(f"Error saving analysis: {str(e)}")
            return False

    async def _get_token_id_by_address(self, token_address: str) -> Optional[int]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ token_id –∑–∞ token_address"""
        try:
            cursor = await self.conn.execute("""
                SELECT id FROM token_ids WHERE token_address = ?
            """, (token_address,))
            row = await cursor.fetchone()
            return row[0] if row else None
        except Exception as e:
            self._debug_print(f"Error getting token_id for {token_address}: {e}")
            return None

    async def _save_dexscreener_data(self, token_id: int, dexscreener_data: Any):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è DexScreener –¥–∞–Ω–∏—Ö –≤ –Ω–æ–≤—ñ —Ç–∞–±–ª–∏—Ü—ñ"""
        try:
            if not isinstance(dexscreener_data, dict) or 'pairs' not in dexscreener_data:
                return
            
            pairs = dexscreener_data.get('pairs', [])
            if not isinstance(pairs, list) or not pairs:
                return
            
            pair = pairs[0]  # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à—É –ø–∞—Ä—É
            if not isinstance(pair, dict):
                return
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Å–Ω–æ–≤–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–∞—Ä—É
            await self.conn.execute("""
                INSERT OR REPLACE INTO dexscreener_pairs (
                    token_id, chain_id, dex_id, url, pair_address,
                    price_native, price_usd, fdv, market_cap, pair_created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                token_id,
                pair.get('chainId'),
                pair.get('dexId'),
                pair.get('url'),
                pair.get('pairAddress'),
                pair.get('priceNative'),
                pair.get('priceUsd'),
                pair.get('fdv'),
                pair.get('marketCap'),
                datetime.fromtimestamp(pair.get('pairCreatedAt', 0) / 1000).isoformat() if pair.get('pairCreatedAt') else None
            ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ base token
            base_token = pair.get('baseToken', {})
            if base_token:
                await self.conn.execute("""
                    INSERT OR REPLACE INTO dexscreener_base_token (
                        token_id, address, name, symbol
                    ) VALUES (?, ?, ?, ?)
                """, (
                    token_id,
                    base_token.get('address'),
                    base_token.get('name'),
                    base_token.get('symbol')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ quote token
            quote_token = pair.get('quoteToken', {})
            if quote_token:
                await self.conn.execute("""
                    INSERT OR REPLACE INTO dexscreener_quote_token (
                        token_id, address, name, symbol
                    ) VALUES (?, ?, ?, ?)
                """, (
                    token_id,
                    quote_token.get('address'),
                    quote_token.get('name'),
                    quote_token.get('symbol')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó
            txns = pair.get('txns', {})
            if txns:
                await self.conn.execute("""
                    INSERT OR REPLACE INTO dexscreener_txns (
                        token_id, m5_buys, m5_sells, h1_buys, h1_sells,
                        h6_buys, h6_sells, h24_buys, h24_sells
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    token_id,
                    txns.get('m5', {}).get('buys'),
                    txns.get('m5', {}).get('sells'),
                    txns.get('h1', {}).get('buys'),
                    txns.get('h1', {}).get('sells'),
                    txns.get('h6', {}).get('buys'),
                    txns.get('h6', {}).get('sells'),
                    txns.get('h24', {}).get('buys'),
                    txns.get('h24', {}).get('sells')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–±'—î–º
            volume = pair.get('volume', {})
            if volume:
                await self.conn.execute("""
                    INSERT OR REPLACE INTO dexscreener_volume (
                        token_id, h24, h6, h1, m5
                    ) VALUES (?, ?, ?, ?, ?)
                """, (
                    token_id,
                    volume.get('h24'),
                    volume.get('h6'),
                    volume.get('h1'),
                    volume.get('m5')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–º—ñ–Ω–∏ —Ü—ñ–Ω–∏
            price_change = pair.get('priceChange', {})
            if price_change:
                await self.conn.execute("""
                    INSERT OR REPLACE INTO dexscreener_price_change (
                        token_id, m5, h1, h6, h24
                    ) VALUES (?, ?, ?, ?, ?)
                """, (
                    token_id,
                    price_change.get('m5'),
                    price_change.get('h1'),
                    price_change.get('h6'),
                    price_change.get('h24')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ª—ñ–∫–≤—ñ–¥–Ω—ñ—Å—Ç—å
            liquidity = pair.get('liquidity', {})
            if liquidity:
                await self.conn.execute("""
                    INSERT OR REPLACE INTO dexscreener_liquidity (
                        token_id, usd, base, quote
                    ) VALUES (?, ?, ?, ?)
                """, (
                    token_id,
                    liquidity.get('usd'),
                    liquidity.get('base'),
                    liquidity.get('quote')
                ))
            
            self._debug_print(f"‚úÖ DexScreener data saved for token_id {token_id}")
            
        except Exception as e:
            self._debug_print(f"Error saving DexScreener data: {e}")

    async def _save_solana_rpc_data(self, token_id: int, solana_rpc_data: Dict[str, Any]):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è Solana RPC –¥–∞–Ω–∏—Ö –≤ –Ω–æ–≤—ñ —Ç–∞–±–ª–∏—Ü—ñ"""
        try:
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ token supply
            token_supply = solana_rpc_data.get('token_supply', {})
            if token_supply and 'value' in token_supply:
                supply_value = token_supply['value']
                context = token_supply.get('context', {})
                await self.conn.execute("""
                    INSERT OR REPLACE INTO solana_token_supply (
                        token_id, amount, decimals, ui_amount, ui_amount_string,
                        slot, api_version
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    token_id,
                    supply_value.get('amount'),
                    supply_value.get('decimals'),
                    supply_value.get('uiAmount'),
                    supply_value.get('uiAmountString'),
                    context.get('slot'),
                    context.get('apiVersion')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ token metadata
            token_metadata = solana_rpc_data.get('token_metadata', {})
            if token_metadata and 'value' in token_metadata:
                metadata_value = token_metadata['value']
                context = token_metadata.get('context', {})
                parsed_info = metadata_value.get('data', {}).get('parsed', {}).get('info', {})
                
                await self.conn.execute("""
                    INSERT OR REPLACE INTO solana_token_metadata (
                        token_id, decimals, freeze_authority, is_initialized,
                        mint_authority, supply, program, space, executable,
                        lamports, owner, rent_epoch, slot, api_version
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    token_id,
                    parsed_info.get('decimals'),
                    parsed_info.get('freezeAuthority'),
                    parsed_info.get('isInitialized'),
                    parsed_info.get('mintAuthority'),
                    parsed_info.get('supply'),
                    metadata_value.get('data', {}).get('program'),
                    metadata_value.get('space'),
                    metadata_value.get('executable'),
                    metadata_value.get('lamports'),
                    metadata_value.get('owner'),
                    metadata_value.get('rentEpoch'),
                    context.get('slot'),
                    context.get('apiVersion')
                ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ recent signatures
            recent_signatures = solana_rpc_data.get('recent_signatures', [])
            if isinstance(recent_signatures, list):
                # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏
                await self.conn.execute("""
                    DELETE FROM solana_recent_signatures WHERE token_id = ?
                """, (token_id,))
                
                # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ
                for sig in recent_signatures:
                    if isinstance(sig, dict):
                        await self.conn.execute("""
                            INSERT INTO solana_recent_signatures (
                                token_id, block_time, confirmation_status, err, memo, signature, slot
                            ) VALUES (?, ?, ?, ?, ?, ?, ?)
                        """, (
                            token_id,
                            sig.get('blockTime'),
                            sig.get('confirmationStatus'),
                            sig.get('err'),
                            sig.get('memo'),
                            sig.get('signature'),
                            sig.get('slot')
                        ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ dev activity
            dev_activity = solana_rpc_data.get('dev_activity', [])
            if isinstance(dev_activity, list):
                # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏
                await self.conn.execute("""
                    DELETE FROM solana_dev_activity WHERE token_id = ?
                """, (token_id,))
                
                # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ
                for activity in dev_activity:
                    if isinstance(activity, dict):
                        await self.conn.execute("""
                            INSERT INTO solana_dev_activity (
                                token_id, block_time, confirmation_status, err, memo, signature, slot
                            ) VALUES (?, ?, ?, ?, ?, ?, ?)
                        """, (
                            token_id,
                            activity.get('blockTime'),
                            activity.get('confirmationStatus'),
                            activity.get('err'),
                            activity.get('memo'),
                            activity.get('signature'),
                            activity.get('slot')
                        ))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ largest accounts
            largest_accounts = solana_rpc_data.get('largest_accounts', {})
            if isinstance(largest_accounts, dict):
                await self.conn.execute("""
                    INSERT OR REPLACE INTO solana_largest_accounts (
                        token_id, error_message
                    ) VALUES (?, ?)
                """, (
                    token_id,
                    largest_accounts.get('error')
                ))
            
            self._debug_print(f"‚úÖ Solana RPC data saved for token_id {token_id}")
            
        except Exception as e:
            self._debug_print(f"Error saving Solana RPC data: {e}")

    async def _update_token_data_from_dexscreener(self, token_id: int, dexscreener_data: Any):
        """–û–Ω–æ–≤–ª–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–∏—Ö –¥–∞–Ω–∏—Ö —Ç–æ–∫–µ–Ω–∞ –∑ DexScreener"""
        try:
            if not isinstance(dexscreener_data, dict) or 'pairs' not in dexscreener_data:
                return
            
            pairs = dexscreener_data.get('pairs', [])
            if not isinstance(pairs, list) or not pairs:
                return
            
            pair = pairs[0]
            if not isinstance(pair, dict):
                return
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –æ—Å–Ω–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤ —Ç–∞–±–ª–∏—Ü—ñ tokens
            await self.conn.execute("""
                UPDATE tokens SET
                    usd_price = ?,
                    liquidity = ?,
                    fdv = ?,
                    mcap = ?,
                    updated_at = CURRENT_TIMESTAMP
                WHERE token_id = ?
            """, (
                pair.get('priceUsd'),
                pair.get('liquidity', {}).get('usd'),
                pair.get('fdv'),
                pair.get('marketCap'),
                token_id
            ))
            
            self._debug_print(f"‚úÖ Token data updated from DexScreener for token_id {token_id}")
            
        except Exception as e:
            self._debug_print(f"Error updating token data from DexScreener: {e}")

    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –ó–º—ñ–Ω–µ–Ω–æ —Ç–∏–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∑ int –Ω–∞ str
    async def _broadcast_token_update(self, token_address: str):
        """–í—ñ–¥–ø—Ä–∞–≤–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–æ–∫–µ–Ω–∞ –Ω–∞ frontend —á–µ—Ä–µ–∑ WebSocket"""
        try:
            self._debug_print(f"üì° Starting broadcast for token_address {token_address}")
            
            # –û—Ç—Ä–∏–º—É—î–º–æ token_id –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
            token_id = await self._get_token_id_by_address(token_address)
            if not token_id:
                self._debug_print(f"‚ùå Token {token_address} not found in token_ids table")
                return
            
            # –û—Ç—Ä–∏–º—É—î–º–æ –æ–Ω–æ–≤–ª–µ–Ω—ñ –¥–∞–Ω—ñ —Ç–æ–∫–µ–Ω–∞
            updated_token = await self._get_updated_token_data(token_id)
            if not updated_token:
                self._debug_print(f"‚ùå No updated token data found for token_id {token_id}")
                return
            
            self._debug_print(f"üìä Token data: {updated_token.get('id')} - DEX: {updated_token.get('dex')} - Pair: {updated_token.get('token_pair')}")
            
            # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ broadcast —Ñ—É–Ω–∫—Ü—ñ—é –∑ main
            import main
            broadcast_data = {
                "success": True,
                "type": "token_update",
                "token": updated_token,
                "timestamp": datetime.now().isoformat()
            }
            
            await main.broadcast_to_clients(broadcast_data)
            
            self._debug_print(f"üì° Broadcasted token update for token_address {token_address}: {updated_token.get('dex', 'N/A')} - {updated_token.get('token_pair', 'N/A')}")
            
        except Exception as e:
            self._debug_print(f"‚ùå Error broadcasting token update: {e}")
            import traceback
            self._debug_print(f"Traceback: {traceback.format_exc()}")

    async def _get_updated_token_data(self, token_id: int) -> Optional[Dict[str, Any]]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –æ–Ω–æ–≤–ª–µ–Ω—ñ –¥–∞–Ω—ñ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è broadcast"""
        try:
            cursor = await self.conn.execute("""
                SELECT 
                    ti.token_address,
                    ti.token_pair,
                    ti.is_honeypot,
                    ti.lp_owner,
                    ti.dev_address,
                    t.name,
                    t.symbol,
                    t.usd_price,
                    t.liquidity,
                    t.fdv,
                    t.mcap,
                    dp.dex_id,
                    dbt.symbol as base_symbol,
                    dqt.symbol as quote_symbol
                FROM token_ids ti
                LEFT JOIN tokens t ON t.token_id = ti.id
                LEFT JOIN dexscreener_pairs dp ON dp.token_id = ti.id
                LEFT JOIN dexscreener_base_token dbt ON dbt.token_id = ti.id
                LEFT JOIN dexscreener_quote_token dqt ON dqt.token_id = ti.id
                WHERE ti.id = ?
            """, (token_id,))
            
            row = await cursor.fetchone()
            if not row:
                return None
            
            return {
                "id": row[0],  # token_address
                "name": row[5],
                "symbol": row[6],
                "mcap": row[10],
                "holders": None,  # –ú–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –∑ —ñ–Ω—à–æ—ó —Ç–∞–±–ª–∏—Ü—ñ
                "dex": row[11] or "Analyzing...",
                "token_pair": row[1] or "Analyzing...",
                "usd_price": row[7],
                "liquidity": row[8],
                "fdv": row[9],
                "is_honeypot": row[2],
                "lp_owner": row[3],
                "dev_address": row[4],
                "base_symbol": row[12],
                "quote_symbol": row[13]
            }
            
        except Exception as e:
            self._debug_print(f"Error getting updated token data: {e}")
            return None

    async def run_analysis_cycle(self):
        """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª—É –∞–Ω–∞–ª—ñ–∑—É –∑ batch –æ–±—Ä–æ–±–∫–æ—é (50 —Ç–æ–∫–µ–Ω—ñ–≤ –∑–∞ —Ä–∞–∑ –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é)"""
        try:
            self._debug_print("üì• Loading tokens needing analysis...")
            # –°–ø–æ—á–∞—Ç–∫—É –¥–æ–¥–∞—î–º–æ —Ç–æ–∫–µ–Ω–∏ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö, —è–∫—ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –∞–Ω–∞–ª—ñ–∑—É
            await self.load_tokens_needing_analysis()
            
            async with self.analysis_lock:
                self._debug_print(f"üìä Analysis queue size: {len(self.analysis_queue)}")
                if not self.analysis_queue:
                    self._debug_print("‚ö†Ô∏è Analysis queue is empty, skipping cycle")
                    return
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 10 —Ç–æ–∫–µ–Ω—ñ–≤ –≤ —á–µ—Ä–∑—ñ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                queue_sample = list(self.analysis_queue.items())[:10]
                self._debug_print(f"üîç First 10 tokens in queue: {[(k, v['iterations_left']) for k, v in queue_sample]}")
                
                # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —Ç–æ–∫–µ–Ω–∏, —è–∫—ñ —â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∏ –∞–Ω–∞–ª—ñ–∑ (iterations_left > 0)
                active_tokens = {
                    token_id: data for token_id, data in self.analysis_queue.items() 
                    if data['iterations_left'] > 0
                }
                
                self._debug_print(f"üìä Active tokens (iterations_left > 0): {len(active_tokens)}")
                if not active_tokens:
                    self._debug_print("‚ö†Ô∏è No active tokens, skipping cycle")
                    return
                
                # –ë–µ—Ä–µ–º–æ –Ω–∞—Å—Ç—É–ø–Ω—ñ 50 —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (—Ä–æ—Ç–∞—Ü—ñ—è)
                tokens_to_analyze = list(active_tokens.keys())[:50]
                self._debug_print(f"üéØ Selected {len(tokens_to_analyze)} tokens for analysis")
            
            if not tokens_to_analyze:
                return
            
            # Batch –∞–Ω–∞–ª—ñ–∑ —á–µ—Ä–µ–∑ Jupiter API
            self._debug_print(f"Starting batch analysis for {len(tokens_to_analyze)} tokens (rotation)")
            batch_results = await self.batch_analyze_tokens(tokens_to_analyze)
            
            # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –î–æ–¥–∞–Ω–æ start_time –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É analysis_time
            cycle_start_time = time.time()
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ batch –∞–Ω–∞–ª—ñ–∑—É
            for token_id in tokens_to_analyze:
                try:
                    if token_id in batch_results:
                        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –∑ batch —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
                        jupiter_data = batch_results[token_id]['jupiter_data']
                        
                        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –¥–∞–Ω—ñ (DexScreener, Solana RPC)
                        dexscreener_data = await self._get_dexscreener_data(token_id)
                        solana_rpc_data = await self._get_solana_rpc_data(token_id)
                        
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
                        iteration = 4 - self.analysis_queue[token_id]['iterations_left']  # 1, 2, 3
                        
                        # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ analysis_time
                        analysis_time = time.time() - cycle_start_time
                        
                        analysis = {
                            'token_address': token_id,
                            'timestamp': datetime.now().isoformat(),
                            'analysis_time': f"{analysis_time:.2f}s",
                            'iteration': iteration,
                            'raw_data': {
                                'jupiter': jupiter_data,
                                'dexscreener': dexscreener_data,
                                'solana_rpc': solana_rpc_data
                            },
                            'security': {
                                # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π honeypot check
                                'honeypot_check': await self._honeypot_with_fallback(token_id, dexscreener_data, solana_rpc_data),
                                # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è LP owner
                                'lp_owner': await self._get_lp_owner(self._extract_pair_from_dexscreener(dexscreener_data)) if self._extract_pair_from_dexscreener(dexscreener_data) else None,
                                'dev_address': self._get_dev_address(jupiter_data)
                            }
                        }
                        
                        # –î–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É
                        self._debug_print(f"üîç ANALYSIS DATA for {token_id} (iteration {iteration}):")
                        self._debug_print(f"  üìä Jupiter data keys: {list(jupiter_data.keys()) if isinstance(jupiter_data, dict) else 'Not a dict'}")
                        self._debug_print(f"  üìä DexScreener data keys: {list(dexscreener_data.keys()) if isinstance(dexscreener_data, dict) else 'Not a dict'}")
                        self._debug_print(f"  üìä Solana RPC data keys: {list(solana_rpc_data.keys()) if isinstance(solana_rpc_data, dict) else 'Not a dict'}")
                        
                        # –õ–æ–≥—É–≤–∞–Ω–Ω—è DexScreener —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
                        if isinstance(dexscreener_data, dict) and 'pairs' in dexscreener_data:
                            pairs = dexscreener_data.get('pairs', [])
                            self._debug_print(f"  üîó DexScreener pairs count: {len(pairs)}")
                            if pairs and isinstance(pairs, list):
                                first_pair = pairs[0]
                                if isinstance(first_pair, dict):
                                    self._debug_print(f"  üîó First pair keys: {list(first_pair.keys())}")
                                    self._debug_print(f"  üîó DexId: {first_pair.get('dexId', 'NOT_FOUND')}")
                        
                        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–Ω–∞–ª—ñ–∑
                        await self.save_analysis(analysis)
                        
                        # –û–Ω–æ–≤–ª—é—î–º–æ —á–∞—Å –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
                        await self.conn.execute("""
                            UPDATE token_ids 
                            SET security_analyzed_at = CURRENT_TIMESTAMP
                            WHERE id = ?
                        """, (token_id,))
                        
                        # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –ü–µ—Ä–µ–¥–∞—î–º–æ token_address –∑–∞–º—ñ—Å—Ç—å token_id
                        await self._broadcast_token_update(token_id)
                        
                        self._debug_print(f"Batch analysis completed for {token_id}, iteration {iteration}")
                    else:
                        self._debug_print(f"No batch data for {token_id}")
                        
                except Exception as e:
                    self._debug_print(f"Error processing {token_id}: {e}")
            
            # –û–Ω–æ–≤–ª—é—î–º–æ —á–µ—Ä–≥—É
            async with self.analysis_lock:
                for token_id in tokens_to_analyze:
                    if token_id in self.analysis_queue:
                        self.analysis_queue[token_id]['iterations_left'] -= 1
                        self.analysis_queue[token_id]['last_analysis'] = datetime.now()
                        
                        # –í–∏–¥–∞–ª—è—î–º–æ —Ç–æ–∫–µ–Ω–∏, —è–∫—ñ –∑–∞–≤–µ—Ä—à–∏–ª–∏ –≤—Å—ñ —ñ—Ç–µ—Ä–∞—Ü—ñ—ó
                        if self.analysis_queue[token_id]['iterations_left'] <= 0:
                            del self.analysis_queue[token_id]
                            self._debug_print(f"Removed {token_id} from analysis queue (completed)")
            
            self._debug_print(f"Batch analysis cycle complete. Queue size: {len(self.analysis_queue)} (active: {len(active_tokens)})")
            
        except Exception as e:
            self._debug_print(f"Analysis cycle error: {e}")

    async def load_tokens_needing_analysis(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–æ–∫–µ–Ω—ñ–≤ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö, —è–∫—ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –∞–Ω–∞–ª—ñ–∑—É"""
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≥–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
            import main
            db = main.db_instance
            await db.ensure_connection()
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–æ–∫–µ–Ω–∏, —è–∫—ñ —â–µ –Ω–µ –º–∞—é—Ç—å token_pair (–Ω–µ –∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ)
            tokens_needing_analysis = await db.get_tokens_needing_analysis(max_checks=3, limit=200)
            
            self._debug_print(f"üìä Found {len(tokens_needing_analysis)} tokens needing analysis")
            
            if tokens_needing_analysis:
                self._debug_print(f"üìã Tokens needing analysis: {tokens_needing_analysis[:3]}...")
            
            # –î–æ–¥–∞—î–º–æ —ó—Ö –¥–æ —á–µ—Ä–≥–∏ –∞–Ω–∞–ª—ñ–∑—É
            added_count = 0
            for token_address in tokens_needing_analysis:
                async with self.analysis_lock:
                    if token_address not in self.analysis_queue:
                        self.analysis_queue[token_address] = {
                            'iterations_left': 3,
                            'last_analysis': None
                        }
                        added_count += 1
                        self._debug_print(f"Added {token_address} to analysis queue")
            
            self._debug_print(f"üìä Added {added_count} tokens from DB to analysis queue. Total queue size: {len(self.analysis_queue)}")
            
        except Exception as e:
            self._debug_print(f"Error loading tokens needing analysis: {str(e)}")
            import traceback
            self._debug_print(f"Traceback: {traceback.format_exc()}")

    async def start_analysis_loop(self):
        """–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª—É –∞–Ω–∞–ª—ñ–∑—É –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é"""
        try:
            self._debug_print("üöÄ Starting analysis loop with rotation (50 tokens every 3 seconds)...")
            
            cycle_count = 0
            while True:
                try:
                    cycle_count += 1
                    self._debug_print(f"üîÑ Analysis cycle #{cycle_count} starting...")
                    await self.run_analysis_cycle()
                    self._debug_print(f"‚úÖ Analysis cycle #{cycle_count} completed, sleeping for 3 seconds...")
                    await asyncio.sleep(3)  # 3 —Å–µ–∫—É–Ω–¥–∏ –º—ñ–∂ —Ü–∏–∫–ª–∞–º–∏ (—Ä–æ—Ç–∞—Ü—ñ—è)
                except Exception as e:
                    self._debug_print(f"‚ùå Error in analysis loop cycle #{cycle_count}: {str(e)}")
                    import traceback
                    self._debug_print(f"Traceback: {traceback.format_exc()}")
                    await asyncio.sleep(3)
        except Exception as e:
            print(f"‚ùå Critical error in analysis loop: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")

    # –ú–µ—Ç–æ–¥–∏ –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö (–∞–¥–∞–ø—Ç–æ–≤–∞–Ω—ñ –∑ _v1_analyzer_SQLite.py)
    
    async def _fetch_with_retries(self, method: str, url: str, **kwargs) -> Dict[str, Any]:
        """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ GET –∑ —Ä–µ—Ç—Ä–∞—è–º–∏"""
        last_exc = None
        for attempt in range(1, RETRY_COUNT + 1):
            try:
                self._debug_print(f"fetch try {attempt} -> {url}")
                async with self.session.get(url, **kwargs) as resp:
                    status = resp.status
                    text = await resp.text()
                    try:
                        parsed = json.loads(text)
                    except Exception:
                        parsed = None
                    if 200 <= status < 300:
                        return {"ok": True, "status": status, "json": parsed, "text": text}
                    else:
                        return {"ok": False, "status": status, "json": parsed, "text": text,
                                "error": f"HTTP {status}"}
            except Exception as e:
                last_exc = e
                backoff = RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) * (1 + random.random() * 0.3)
                self._debug_print(f"fetch error {e}, backoff {backoff:.2f}s")
                await asyncio.sleep(backoff)
        return {"ok": False, "status": None, "json": None, "text": None, "error": str(last_exc)}

    async def _post_rpc_with_retries(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """RPC POST –∑ —Ä–µ—Ç—Ä–∞—è–º–∏"""
        last_exc = None
        for attempt in range(1, RETRY_COUNT + 1):
            try:
                self._debug_print("rpc try", attempt, payload.get("method"))
                async with self.session.post(self.solana_rpc_url, json=payload, timeout=10) as resp:
                    status = resp.status
                    data = await resp.json(content_type=None)
                    if 200 <= status < 300:
                        return {"ok": True, "status": status, "json": data}
                    else:
                        return {"ok": False, "status": status, "json": data, "error": f"HTTP {status}"}
            except Exception as e:
                last_exc = e
                backoff = RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) * (1 + random.random() * 0.3)
                self._debug_print(f"rpc error {e}, backoff {backoff:.2f}s")
                await asyncio.sleep(backoff)
        return {"ok": False, "status": None, "json": None, "error": str(last_exc)}

    async def _get_jupiter_data(self, token_address: str) -> Any:
        try:
            url = f"https://lite-api.jup.ag/tokens/v2/search?query={token_address}"
            self._debug_print(f"ü™ê Fetching Jupiter data for {token_address}")
            res = await self._fetch_with_retries("GET", url, headers={"User-Agent": "Mozilla/5.0"})
            if res["ok"]:
                data = res["json"]
                if isinstance(data, list) and data:
                    self._debug_print(f"  ü™ê Jupiter returned {len(data)} tokens")
                    first_token = data[0]
                    if isinstance(first_token, dict):
                        self._debug_print(f"  ü™ê First token name: {first_token.get('name', 'UNKNOWN')}")
                        self._debug_print(f"  ü™ê First token symbol: {first_token.get('symbol', 'UNKNOWN')}")
                return data
            else:
                self._debug_print(f"  ‚ùå Jupiter error: {res.get('error')}")
                return {"error": res.get("error") or f"HTTP {res.get('status')}"}
        except Exception as e:
            self._debug_print(f"  ‚ùå Jupiter exception: {str(e)}")
            return {"error": str(e)}

    async def _get_dexscreener_data(self, token_address: str) -> Any:
        try:
            url = f"https://api.dexscreener.com/latest/dex/search/?q={token_address}"
            self._debug_print(f"üîó Fetching DexScreener data for {token_address}")
            res = await self._fetch_with_retries("GET", url)
            if res["ok"]:
                data = res["json"]
                if isinstance(data, dict) and 'pairs' in data:
                    pairs = data.get('pairs', [])
                    self._debug_print(f"  üîó DexScreener returned {len(pairs)} pairs")
                    
                    # –Ø–∫—â–æ pairs –ø–æ—Ä–æ–∂–Ω—ñ–π, —Å–ø—Ä–æ–±—É—î–º–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π API
                    if not pairs or len(pairs) == 0:
                        self._debug_print(f"  ‚ö†Ô∏è Empty pairs, trying alternative DexScreener API...")
                        alt_url = f"https://api.dexscreener.com/latest/dex/tokens/{token_address}"
                        alt_res = await self._fetch_with_retries("GET", alt_url)
                        if alt_res["ok"] and isinstance(alt_res["json"], dict):
                            alt_data = alt_res["json"]
                            if 'pairs' in alt_data and alt_data['pairs']:
                                self._debug_print(f"  ‚úÖ Alternative API returned {len(alt_data['pairs'])} pairs")
                                return alt_data
                    
                    if pairs and isinstance(pairs, list):
                        first_pair = pairs[0]
                        if isinstance(first_pair, dict):
                            self._debug_print(f"  üîó First pair dexId: {first_pair.get('dexId', 'MISSING')}")
                return data
            else:
                self._debug_print(f"  ‚ùå DexScreener error: {res.get('error')}")
                return {"error": res.get("error") or f"HTTP {res.get('status')}"}
        except Exception as e:
            self._debug_print(f"  ‚ùå DexScreener exception: {str(e)}")
            return {"error": str(e)}

    async def _get_solana_rpc_data(self, token_address: str) -> Dict[str, Any]:
        rpc_data: Dict[str, Any] = {}
        
        # getAccountInfo
        payload = {"jsonrpc": "2.0", "id": 1, "method": "getAccountInfo", "params": [token_address, {"encoding": "json"}]}
        res = await self._post_rpc_with_retries(payload)
        rpc_data["token_account_info"] = res["json"].get("result") if res["ok"] and res.get("json") else None

        # getTokenSupply
        payload = {"jsonrpc": "2.0", "id": 1, "method": "getTokenSupply", "params": [token_address]}
        res = await self._post_rpc_with_retries(payload)
        rpc_data["token_supply"] = res["json"].get("result") if res["ok"] and res.get("json") else None

        # getAccountInfo jsonParsed (metadata)
        payload = {"jsonrpc": "2.0", "id": 1, "method": "getAccountInfo", "params": [token_address, {"encoding": "jsonParsed"}]}
        res = await self._post_rpc_with_retries(payload)
        rpc_data["token_metadata"] = res["json"].get("result") if res["ok"] and res.get("json") else None

        # getSignaturesForAddress (recent)
        payload = {"jsonrpc": "2.0", "id": 1, "method": "getSignaturesForAddress", "params": [token_address, {"limit": 12}]}
        res = await self._post_rpc_with_retries(payload)
        signatures = res["json"].get("result") if res["ok"] and res.get("json") else []
        rpc_data["recent_signatures"] = signatures

        # Fetch transactions for analysis
        txs = []
        if isinstance(signatures, list):
            for sig_item in signatures[:6]:
                sig = sig_item.get("signature") if isinstance(sig_item, dict) else sig_item
                if not sig:
                    continue
                payload = {"jsonrpc": "2.0", "id": 1, "method": "getTransaction", "params": [sig, {"encoding": "jsonParsed"}]}
                r = await self._post_rpc_with_retries(payload)
                if r["ok"] and r.get("json"):
                    txs.append(r["json"].get("result"))
        rpc_data["recent_transactions_parsed"] = txs
        
        return rpc_data

    async def _get_token_holders(self, token_address: str) -> Dict[str, Any]:
        try:
            payload = {"jsonrpc": "2.0", "id": 1, "method": "getTokenLargestAccounts", "params": [token_address]}
            res = await self._post_rpc_with_retries(payload)
            if res["ok"] and res.get("json"):
                result = res["json"].get("result")
                if isinstance(result, dict):
                    val = result.get("value")
                    if isinstance(val, list):
                        return {"value": val}
                if isinstance(result, list):
                    return {"value": result}
            return {"error": res.get("error") or "no_result"}
        except Exception as e:
            return {"error": str(e)}

    async def _get_dev_activity(self, dev_address: str) -> Optional[List[Dict[str, Any]]]:
        if not dev_address:
            return None
        try:
            payload = {"jsonrpc": "2.0", "id": 1, "method": "getSignaturesForAddress", "params": [dev_address, {"limit": 10}]}
            res = await self._post_rpc_with_retries(payload)
            if res["ok"] and res.get("json"):
                return res["json"].get("result")
            return None
        except Exception:
            return None

    async def _get_lp_owner(self, pair_address: str) -> Optional[str]:
        if not pair_address:
            return None
        try:
            payload = {"jsonrpc": "2.0", "id": 1, "method": "getAccountInfo", "params": [pair_address, {"encoding": "jsonParsed"}]}
            res = await self._post_rpc_with_retries(payload)
            if res["ok"] and res.get("json"):
                account = res["json"].get("result", {}).get("value")
                if isinstance(account, dict):
                    return account.get("owner")
            return None
        except Exception:
            return None

    async def _honeypot_with_fallback(self, token_address: str, dexscreener_data: Any, solana_rpc_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Honeypot check –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º fallback
        
        –°—Ç—Ä–∞—Ç–µ–≥—ñ—è:
        1. Jupiter Quote API (–æ—Å–Ω–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ - –Ω–∞–π—Ç–æ—á–Ω—ñ—à–∏–π)
        2. Solana RPC transactions (fallback –¥–ª—è –º–æ–ª–æ–¥–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤)
        
        –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ DexScreener –¥–ª—è –º–æ–ª–æ–¥–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤ (< 5 —Ö–≤–∏–ª–∏–Ω),
        –±–æ –≤ –Ω–∏—Ö —â–µ –Ω–µ–º–∞—î —ñ—Å—Ç–æ—Ä—ñ—ó —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π
        """
        result = {
            "checked_by": [],
            "buy_possible": None,
            "sell_possible": None,
            "honeypot": None,
            "reasons": [],
            "token_age_seconds": None
        }

        # 1Ô∏è‚É£ –ú–ï–¢–û–î 1: Jupiter Quote API (–æ—Å–Ω–æ–≤–Ω–∏–π)
        self._debug_print("üîç Honeypot check: trying Jupiter Quote API...")
        try:
            # –°–ø—Ä–æ–±—É—î–º–æ –∫—É–ø–∏—Ç–∏ —Ç–æ–∫–µ–Ω (SOL ‚Üí Token)
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ lite-api.jup.ag/swap/v1/quote (–Ω–æ–≤–∏–π endpoint)
            quote_buy_url = f"https://lite-api.jup.ag/swap/v1/quote?inputMint=So11111111111111111111111111111111111111112&outputMint={token_address}&amount=100000000&slippageBps=50&restrictIntermediateTokens=true"
            # –°–ø—Ä–æ–±—É—î–º–æ –ø—Ä–æ–¥–∞—Ç–∏ —Ç–æ–∫–µ–Ω (Token ‚Üí SOL)
            quote_sell_url = f"https://lite-api.jup.ag/swap/v1/quote?inputMint={token_address}&outputMint=So11111111111111111111111111111111111111112&amount=100000000&slippageBps=50&restrictIntermediateTokens=true"
            
            buy_res = await self._fetch_with_retries("GET", quote_buy_url)
            sell_res = await self._fetch_with_retries("GET", quote_sell_url)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î outAmount (—Å—É–º–∞ —è–∫—É –æ—Ç—Ä–∏–º–∞—î–º–æ)
            can_buy = False
            can_sell = False
            
            if buy_res["ok"] and buy_res.get("json"):
                buy_data = buy_res["json"]
                can_buy = bool(buy_data.get('outAmount')) and not buy_data.get('error')
                
            if sell_res["ok"] and sell_res.get("json"):
                sell_data = sell_res["json"]
                can_sell = bool(sell_data.get('outAmount')) and not sell_data.get('error')
            
            # –Ø–∫—â–æ —Ö–æ—á–∞ –± –æ–¥–∏–Ω –∑–∞–ø–∏—Ç —É—Å–ø—ñ—à–Ω–∏–π - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if buy_res["ok"] or sell_res["ok"]:
                result["checked_by"] = ["jupiter_quote_api"]
                result["buy_possible"] = can_buy
                result["sell_possible"] = can_sell
                result["honeypot"] = not can_sell  # –Ø–∫—â–æ –Ω–µ –º–æ–∂–Ω–∞ –ø—Ä–æ–¥–∞—Ç–∏ - honeypot
                
                if can_buy and can_sell:
                    result["reasons"].append("‚úÖ Jupiter: can BUY and SELL - NOT honeypot")
                elif can_buy and not can_sell:
                    result["reasons"].append("‚ö†Ô∏è Jupiter: can BUY but CANNOT SELL - HONEYPOT!")
                elif not can_buy and can_sell:
                    result["reasons"].append("‚ö†Ô∏è Jupiter: CANNOT BUY but can SELL - unusual")
                else:
                    result["reasons"].append("‚ùå Jupiter: CANNOT BUY and CANNOT SELL - check liquidity")
                
                self._debug_print(f"‚úÖ Jupiter check: buy={can_buy}, sell={can_sell}, honeypot={result['honeypot']}")
                return result
                
        except Exception as e:
            self._debug_print(f"‚ùå Jupiter Quote API error: {e}")
            result["reasons"].append(f"Jupiter API error: {str(e)}")

        # 2Ô∏è‚É£ FALLBACK: Solana RPC transactions (–¥–ª—è –º–æ–ª–æ–¥–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤)
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —è–∫—â–æ solana_rpc_data –ø–æ—Ä–æ–∂–Ω—ñ–π (—à–≤–∏–¥–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞)
        if not solana_rpc_data or not solana_rpc_data.get("recent_transactions_parsed"):
            self._debug_print("‚ö†Ô∏è No RPC data provided, skipping fallback")
            if not result["checked_by"]:
                result["checked_by"] = ["jupiter_quote_api_failed"]
                result["reasons"].append("‚ö†Ô∏è Jupiter failed and no RPC data for fallback")
                result["honeypot"] = None
            return result
        
        self._debug_print("üîç Honeypot check: fallback to RPC transactions...")
        try:
            parsed_txs = solana_rpc_data.get("recent_transactions_parsed", [])
            sells_found = 0
            buys_found = 0
            
            for tx in parsed_txs:
                if not isinstance(tx, dict):
                    continue
                    
                meta = tx.get("meta") or {}
                post_token_balances = meta.get("postTokenBalances") or []
                pre_token_balances = meta.get("preTokenBalances") or []
                
                try:
                    for i_pre in pre_token_balances:
                        for i_post in post_token_balances:
                            if i_pre.get("mint") == i_post.get("mint") == token_address:
                                pre_amount = float(i_pre.get("uiTokenAmount", {}).get("uiAmount") or 0)
                                post_amount = float(i_post.get("uiTokenAmount", {}).get("uiAmount") or 0)
                                
                                if post_amount < pre_amount:
                                    sells_found += 1  # –ë–∞–ª–∞–Ω—Å –∑–º–µ–Ω—à–∏–≤—Å—è = –ø—Ä–æ–¥–∞–∂
                                elif post_amount > pre_amount:
                                    buys_found += 1   # –ë–∞–ª–∞–Ω—Å –∑–±—ñ–ª—å—à–∏–≤—Å—è = –∫—É–ø—ñ–≤–ª—è
                                break
                except Exception:
                    pass
            
            result["checked_by"].append("rpc_recent_txs")
            result["buy_possible"] = buys_found > 0
            result["sell_possible"] = sells_found > 0
            result["honeypot"] = not (sells_found > 0)
            
            if sells_found > 0:
                result["reasons"].append(f"‚úÖ RPC: found {sells_found} sells, {buys_found} buys - NOT honeypot")
            else:
                result["reasons"].append(f"‚ö†Ô∏è RPC: found 0 sells, {buys_found} buys - possibly honeypot or very new token")
            
            self._debug_print(f"‚úÖ RPC check: sells={sells_found}, buys={buys_found}, honeypot={result['honeypot']}")
            
        except Exception as e:
            self._debug_print(f"‚ùå RPC fallback error: {e}")
            result["reasons"].append(f"RPC error: {str(e)}")

        # –Ø–∫—â–æ –∂–æ–¥–µ–Ω –º–µ—Ç–æ–¥ –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤
        if not result["checked_by"]:
            result["checked_by"] = ["none"]
            result["reasons"].append("‚ö†Ô∏è All methods failed - network issues or APIs down")
            result["honeypot"] = None

        return result

    def _extract_dev_from_jupiter(self, jupiter_data: Any) -> Optional[str]:
        try:
            if isinstance(jupiter_data, list) and jupiter_data:
                first = jupiter_data[0]
                return first.get("dev") or first.get("dev_address") or first.get("devAddress")
            if isinstance(jupiter_data, dict):
                if "dev_address" in jupiter_data:
                    return jupiter_data.get("dev_address")
                for k in ("dev", "dev_address", "devAddress"):
                    if k in jupiter_data:
                        return jupiter_data.get(k)
            return None
        except Exception:
            return None

    def _extract_pair_from_dexscreener(self, dexscreener_data: Any) -> Optional[str]:
        try:
            if isinstance(dexscreener_data, dict):
                pairs = dexscreener_data.get("pairs") or []
                if isinstance(pairs, list) and pairs:
                    p0 = pairs[0]
                    return p0.get("pairAddress") or p0.get("pairAddress".lower())
            return None
        except Exception:
            return None

    def _check_honeypot(self, jupiter_data: Any) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–∏–π honeypot check –Ω–∞ –æ—Å–Ω–æ–≤—ñ Jupiter –¥–∞–Ω–∏—Ö"""
        try:
            if isinstance(jupiter_data, list) and jupiter_data:
                token = jupiter_data[0]
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –ø—Ä–æ–¥–∞–∂—ñ
                stats = token.get('stats24h', {})
                sells = stats.get('numSells', 0)
                return {
                    "checked_by": ["jupiter_stats"],
                    "buy_possible": True,
                    "sell_possible": sells > 0,
                    "honeypot": sells == 0,
                    "reasons": [f"Jupiter stats: {sells} sells in 24h"]
                }
            return {
                "checked_by": ["none"],
                "buy_possible": None,
                "sell_possible": None,
                "honeypot": None,
                "reasons": ["No Jupiter data available"]
            }
        except Exception as e:
            return {
                "checked_by": ["error"],
                "buy_possible": None,
                "sell_possible": None,
                "honeypot": None,
                "reasons": [f"Error: {str(e)}"]
            }

    def _get_lp_owner(self, solana_rpc_data: Dict[str, Any]) -> Optional[str]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ LP owner –∑ Solana RPC –¥–∞–Ω–∏—Ö"""
        try:
            # –®—É–∫–∞—î–º–æ –≤ largest_accounts
            largest_accounts = solana_rpc_data.get('largest_accounts', {})
            if isinstance(largest_accounts, dict) and 'value' in largest_accounts:
                accounts = largest_accounts['value']
                if isinstance(accounts, list) and accounts:
                    # –ü–µ—Ä—à–∏–π –∞–∫–∫–∞—É–Ω—Ç –∑–∞–∑–≤–∏—á–∞–π LP
                    return accounts[0].get('address')
            return None
        except Exception:
            return None

    def _get_dev_address(self, jupiter_data: Any) -> Optional[str]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ dev address –∑ Jupiter –¥–∞–Ω–∏—Ö"""
        try:
            if isinstance(jupiter_data, list) and jupiter_data:
                token = jupiter_data[0]
                return token.get('dev')
            return None
        except Exception:
            return None
    
    async def analyze_risk_quick(self, token_address: str) -> Dict[str, Any]:
        """
        üö® –®–í–ò–î–ö–ò–ô –ê–ù–ê–õ–Ü–ó –†–ò–ó–ò–ö–Ü–í –¢–û–ö–ï–ù–ê
        
        –ü–µ—Ä–µ–≤—ñ—Ä—è—î –¢–Ü–õ–¨–ö–ò honeypot –±–µ–∑ –∑–∞–π–≤–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤:
        ‚úÖ Jupiter Quote API (2 –∑–∞–ø–∏—Ç–∏) - BUY/SELL check
        
        –ë–ï–ó –∑–∞–π–≤–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤ –¥–æ Solana RPC!
        
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è —à–≤–∏–¥–∫–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –ø–µ—Ä–µ–¥ –∫—É–ø—ñ–≤–ª–µ—é
        """
        start_time = time.time()
        
        try:
            await self.ensure_session()
            
            self._debug_print(f"\n{'='*60}")
            self._debug_print(f"üö® QUICK HONEYPOT CHECK: {token_address}")
            self._debug_print(f"{'='*60}")
            
            # üéØ –¢–Ü–õ–¨–ö–ò Jupiter honeypot check (2 –∑–∞–ø–∏—Ç–∏)
            self._debug_print("\nüîç Honeypot check (Jupiter Quote API)...")
            honeypot_result = await self._honeypot_with_fallback(
                token_address,
                {},  # –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ DexScreener
                {}   # –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Solana RPC (fallback –≤—ñ–¥–∫–ª—é—á–µ–Ω–∏–π)
            )
            
            # ‚ö° –Ø–∫—â–æ honeypot=TRUE ‚Üí –æ–¥—Ä–∞–∑—É –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ CRITICAL
            if honeypot_result.get('honeypot') is True:
                analysis_time = time.time() - start_time
                result = {
                    "success": True,
                    "token_address": token_address,
                    "timestamp": datetime.now().isoformat(),
                    "analysis_time": f"{analysis_time:.2f}s",
                    "risk_analysis": {
                        "honeypot_check": honeypot_result,
                        "token_age_seconds": None,
                        "token_created_at": None,
                        "is_very_new": None
                    },
                    "risk_level": "CRITICAL"
                }
                
                self._debug_print(f"\n{'='*60}")
                self._debug_print(f"‚õî HONEYPOT DETECTED - STOPPING")
                self._debug_print(f"   Risk level: CRITICAL")
                self._debug_print(f"{'='*60}\n")
                
                return result
            
            # ‚úÖ Honeypot=FALSE ‚Üí —Ç–æ–∫–µ–Ω –±–µ–∑–ø–µ—á–Ω–∏–π
            analysis_time = time.time() - start_time
            
            result = {
                "success": True,
                "token_address": token_address,
                "timestamp": datetime.now().isoformat(),
                "analysis_time": f"{analysis_time:.2f}s",
                "risk_analysis": {
                    "honeypot_check": honeypot_result,
                    "token_age_seconds": None,  # –ù–µ –∑–∞–ø–∏—Ç—É—î–º–æ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
                    "token_created_at": None,
                    "is_very_new": None
                },
                "risk_level": self._calculate_risk_level(honeypot_result, None)
            }
            
            self._debug_print(f"\n{'='*60}")
            self._debug_print(f"‚úÖ HONEYPOT CHECK COMPLETE")
            self._debug_print(f"   Honeypot: {honeypot_result.get('honeypot')}")
            self._debug_print(f"   Risk level: {result['risk_level']}")
            self._debug_print(f"{'='*60}\n")
            
            return result
            
        except Exception as e:
            self._debug_print(f"‚ùå Error in quick risk analysis: {e}")
            import traceback
            return {
                "success": False,
                "token_address": token_address,
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "traceback": traceback.format_exc()
            }
    
    async def analyze_token_full(self, token_address: str) -> Dict[str, Any]:
        """
        üìä –ü–û–í–ù–ò–ô –ê–ù–ê–õ–Ü–ó –¢–û–ö–ï–ù–ê (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –≤–µ—Ä—Å—ñ—è)
        
        –ü–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å (–∑ early exit):
        1Ô∏è‚É£ Jupiter Honeypot Check ‚Üí —è–∫—â–æ TRUE ‚Üí –°–¢–û–ü ‚õî
        2Ô∏è‚É£ Jupiter Token Info ‚Üí name, symbol, dev
        3Ô∏è‚É£ DexScreener ‚Üí —Ç–æ—Ä–≥–æ–≤–∞ –ø–∞—Ä–∞, –ª—ñ–∫–≤—ñ–¥–Ω—ñ—Å—Ç—å
        4Ô∏è‚É£ Solana RPC ‚Üí supply, metadata (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        """
        start_time = time.time()
        
        try:
            await self.ensure_session()
            
            self._debug_print(f"\n{'='*60}")
            self._debug_print(f"üìä FULL TOKEN ANALYSIS: {token_address}")
            self._debug_print(f"{'='*60}")
            
            # 1Ô∏è‚É£ –ö–†–û–ö 1: Honeypot check (–ö–†–ò–¢–ò–ß–ù–û!)
            self._debug_print("\n1Ô∏è‚É£ Step 1: Honeypot check...")
            honeypot_result = await self._honeypot_with_fallback(token_address, {}, {})
            
            # ‚ö†Ô∏è –Ø–∫—â–æ honeypot=TRUE ‚Üí –æ–¥—Ä–∞–∑—É –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —ñ –∑—É–ø–∏–Ω—è—î–º–æ –∞–Ω–∞–ª—ñ–∑
            if honeypot_result.get('honeypot') is True:
                analysis_time = time.time() - start_time
                self._debug_print(f"\n‚õî HONEYPOT DETECTED! Stopping analysis.")
                
                return {
                    "success": True,
                    "token_address": token_address,
                    "timestamp": datetime.now().isoformat(),
                    "analysis_time": f"{analysis_time:.2f}s",
                    "risk_level": "CRITICAL",
                    "honeypot_check": honeypot_result,
                    "jupiter_data": None,
                    "dexscreener_data": None,
                    "solana_rpc_data": None,
                    "stopped_at": "honeypot_check",
                    "reason": "Token is honeypot - stopped analysis"
                }
            
            # ‚úÖ Honeypot=FALSE ‚Üí –ø—Ä–æ–¥–æ–≤–∂—É—î–º–æ
            self._debug_print(f"‚úÖ NOT honeypot, continuing analysis...")
            
            # 2Ô∏è‚É£ –ö–†–û–ö 2: Jupiter token info
            self._debug_print("\n2Ô∏è‚É£ Step 2: Jupiter token info...")
            jupiter_data = await self._get_jupiter_data(token_address)
            
            # 3Ô∏è‚É£ –ö–†–û–ö 3: DexScreener
            self._debug_print("\n3Ô∏è‚É£ Step 3: DexScreener data...")
            dexscreener_data = await self._get_dexscreener_data(token_address)
            
            # 4Ô∏è‚É£ –ö–†–û–ö 4: Solana RPC (–±–∞–∑–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è - 2 –∑–∞–ø–∏—Ç–∏)
            self._debug_print("\n4Ô∏è‚É£ Step 4: Solana RPC (basic info)...")
            solana_rpc_data = await self._get_solana_rpc_basic(token_address)
            
            # –§–æ—Ä–º—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            analysis_time = time.time() - start_time
            
            # –í–∏—Ç—è–≥—É—î–º–æ dev address
            dev_address = self._extract_dev_from_jupiter(jupiter_data)
            
            # –í–∏—Ç—è–≥—É—î–º–æ pair address
            pair_address = self._extract_pair_from_dexscreener(dexscreener_data)
            
            result = {
                "success": True,
                "token_address": token_address,
                "timestamp": datetime.now().isoformat(),
                "analysis_time": f"{analysis_time:.2f}s",
                "risk_level": self._calculate_risk_level(honeypot_result, None),
                "security": {
                    "honeypot_check": honeypot_result,
                    "dev_address": dev_address,
                    "pair_address": pair_address
                },
                "jupiter_data": jupiter_data,
                "dexscreener_data": dexscreener_data,
                "solana_rpc_data": solana_rpc_data
            }
            
            self._debug_print(f"\n{'='*60}")
            self._debug_print(f"‚úÖ FULL ANALYSIS COMPLETE")
            self._debug_print(f"   Honeypot: {honeypot_result.get('honeypot')}")
            self._debug_print(f"   Dev address: {dev_address or 'N/A'}")
            self._debug_print(f"   Pair address: {pair_address or 'N/A'}")
            self._debug_print(f"   Risk level: {result['risk_level']}")
            self._debug_print(f"   Time: {analysis_time:.2f}s")
            self._debug_print(f"{'='*60}\n")
            
            return result
            
        except Exception as e:
            self._debug_print(f"‚ùå Error in full analysis: {e}")
            import traceback
            return {
                "success": False,
                "token_address": token_address,
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "traceback": traceback.format_exc()
            }
    
    async def _get_solana_rpc_basic(self, token_address: str) -> Dict[str, Any]:
        """
        –ë–∞–∑–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –∑ Solana RPC (—Ç—ñ–ª—å–∫–∏ 2 –∑–∞–ø–∏—Ç–∏)
        
        –û—Ç—Ä–∏–º—É—î:
        - Token supply (–∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤)
        - Token metadata (decimals, mint authority)
        """
        rpc_data: Dict[str, Any] = {}
        
        # 1. getTokenSupply
        self._debug_print("   ‚Üí getTokenSupply")
        payload = {"jsonrpc": "2.0", "id": 1, "method": "getTokenSupply", "params": [token_address]}
        res = await self._post_rpc_with_retries(payload)
        rpc_data["token_supply"] = res["json"].get("result") if res["ok"] and res.get("json") else None

        # 2. getAccountInfo jsonParsed (metadata)
        self._debug_print("   ‚Üí getAccountInfo (metadata)")
        payload = {"jsonrpc": "2.0", "id": 1, "method": "getAccountInfo", "params": [token_address, {"encoding": "jsonParsed"}]}
        res = await self._post_rpc_with_retries(payload)
        rpc_data["token_metadata"] = res["json"].get("result") if res["ok"] and res.get("json") else None
        
        return rpc_data
    
    def _calculate_risk_level(self, honeypot_result: Dict[str, Any], token_age_seconds: Optional[int]) -> str:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ä—ñ–≤–Ω—è —Ä–∏–∑–∏–∫—É
        
        Returns:
            "CRITICAL" - –¥—É–∂–µ –Ω–µ–±–µ–∑–ø–µ—á–Ω–æ
            "HIGH" - –≤–∏—Å–æ–∫–∏–π —Ä–∏–∑–∏–∫
            "MEDIUM" - —Å–µ—Ä–µ–¥–Ω—ñ–π —Ä–∏–∑–∏–∫
            "LOW" - –Ω–∏–∑—å–∫–∏–π —Ä–∏–∑–∏–∫
            "UNKNOWN" - –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö
        """
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ honeypot
        is_honeypot = honeypot_result.get('honeypot')
        
        if is_honeypot is True:
            return "CRITICAL"  # –¢–æ—á–Ω–æ honeypot
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤—ñ–∫—É —Ç–æ–∫–µ–Ω–∞
        if token_age_seconds:
            if token_age_seconds < 60:  # < 1 —Ö–≤–∏–ª–∏–Ω–∏
                return "HIGH"  # –î—É–∂–µ –º–æ–ª–æ–¥–∏–π, –Ω–µ–º–∞—î —ñ—Å—Ç–æ—Ä—ñ—ó
            elif token_age_seconds < 300:  # < 5 —Ö–≤–∏–ª–∏–Ω
                return "MEDIUM"  # –ú–æ–ª–æ–¥–∏–π, –º–∞–ª–æ –¥–∞–Ω–∏—Ö
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º–µ—Ç–æ–¥—ñ–≤
        checked_by = honeypot_result.get('checked_by', [])
        if 'jupiter_quote_api' in checked_by and is_honeypot is False:
            return "LOW"  # Jupiter –ø—ñ–¥—Ç–≤–µ—Ä–¥–∏–≤ –±–µ–∑–ø–µ—á–Ω—ñ—Å—Ç—å
        
        if is_honeypot is False:
            return "LOW"  # NOT honeypot
        
        return "UNKNOWN"  # –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö

# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞
analyzer_instance: Optional[AsyncTokenAnalyzer] = None

async def get_analyzer() -> AsyncTokenAnalyzer:
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –≥–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞"""
    global analyzer_instance
    if analyzer_instance is None:
        analyzer_instance = AsyncTokenAnalyzer(debug=True)
    return analyzer_instance

async def start_analyzer():
    """–ó–∞–ø—É—Å—Ç–∏—Ç–∏ –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä"""
    try:
        print("üîç Initializing analyzer...")
        analyzer = await get_analyzer()
        print("üöÄ Starting analyzer background task...")
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –≤ –æ–∫—Ä–µ–º—ñ–π –∑–∞–¥–∞—á—ñ, —â–æ–± –Ω–µ –±–ª–æ–∫—É–≤–∞—Ç–∏ —Å–µ—Ä–≤–µ—Ä
        asyncio.create_task(analyzer.start_analysis_loop())
        print("‚úÖ Analyzer started successfully")
    except Exception as e:
        print(f"‚ùå Error starting analyzer: {e}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")

async def add_tokens_for_analysis(token_addresses: List[str]):
    """–î–æ–¥–∞—Ç–∏ —Ç–æ–∫–µ–Ω–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É"""
    print(f"üîç Adding {len(token_addresses)} tokens for analysis: {token_addresses[:3]}...")
    analyzer = await get_analyzer()
    await analyzer.add_tokens_to_analysis(token_addresses)
    print(f"‚úÖ Added tokens to analysis queue. Queue size: {len(analyzer.analysis_queue)}")

async def stop_analyzer():
    """–ó—É–ø–∏–Ω–∏—Ç–∏ –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä"""
    global analyzer_instance
    if analyzer_instance:
        await analyzer_instance.close()
        analyzer_instance = None
