#!/usr/bin/env python3

import asyncio
import aiohttp
import json
import random
from typing import Dict, Any, Optional, List
from datetime import datetime
from _v2_db_pool import get_db_pool
from config import config

class JupiterAnalyzer:
    """
    Jupiter API analyzer –¥–ª—è –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Ç–∞–±–ª–∏—Ü—å (stats, audit, firstPool, tags)
    
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Jupiter Search API:
    https://lite-api.jup.ag/tokens/v2/search?query={token_address}
    
    –ê–Ω–∞–ª–æ–≥—ñ—á–Ω–æ –¥–æ DexScreenerAnalyzer, –∞–ª–µ –¥–ª—è Jupiter –¥–∞–Ω–∏—Ö.
    """
    
    def __init__(self, db_path: str = "db/tokens.db", debug: bool = False):
        self.session: Optional[aiohttp.ClientSession] = None
        self.debug = debug
        
        # Auto-scan –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
        self.is_scanning = False
        self.scan_interval = config.JUPITER_ANALYZER_INTERVAL
        self.scan_task: Optional[asyncio.Task] = None
        self.batch_size = config.JUPITER_ANALYZER_BATCH_SIZE
        
        # Cursor –¥–ª—è –ø–∞–≥—ñ–Ω–∞—Ü—ñ—ó (–∑–∞–ø–∞–º'—è—Ç–æ–≤—É—î–º–æ –¥–µ –∑—É–ø–∏–Ω–∏–ª–∏—Å—å)
        self.last_processed_id = 0  # ID –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
        
    async def ensure_connection(self):
        """PostgreSQL - pool created globally"""
        pass
        
    async def ensure_session(self):
        if self.session is None:
            self.session = aiohttp.ClientSession()
    
    async def close(self):
        if self.session:
            await self.session.close()
    
    async def _fetch_with_retries(self, url: str, **kwargs) -> Dict[str, Any]:
        """–ó–∞–ø–∏—Ç –∑ retry –ª–æ–≥—ñ–∫–æ—é"""
        last_exc = None
        for attempt in range(1, 4):
            try:
                async with self.session.get(url, **kwargs) as resp:
                    status = resp.status
                    text = await resp.text()
                    try:
                        parsed = json.loads(text)
                    except Exception:
                        parsed = None
                    if 200 <= status < 300:
                        return {"ok": True, "status": status, "json": parsed}
                    else:
                        return {"ok": False, "status": status, "json": parsed, "error": f"HTTP {status}"}
            except Exception as e:
                last_exc = e
                backoff = 0.4 * (2 ** (attempt - 1)) * (1 + random.random() * 0.3)
                await asyncio.sleep(backoff)
        return {"ok": False, "error": str(last_exc)}
    
    async def get_tokens_data_batch(self, token_addresses: List[str]) -> Any:
        """
        –û—Ç—Ä–∏–º—É—î –¥–∞–Ω—ñ –¥–ª—è –ë–ê–ì–ê–¢–¨–û–• —Ç–æ–∫–µ–Ω—ñ–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ –∑ Jupiter Search API
        
        https://lite-api.jup.ag/tokens/v2/search?query={address1,address2,address3,...}
        
        Limit: 100 —Ç–æ–∫–µ–Ω—ñ–≤ –∑–∞ –∑–∞–ø–∏—Ç
        """
        try:
            await self.ensure_session()
            
            # Comma-separated —Å–ø–∏—Å–æ–∫ mint addresses
            query = ",".join(token_addresses[:100])  # Jupiter limit: 100 addresses
            url = f"{config.JUPITER_SEARCH_API}?query={query}"
            
            res = await self._fetch_with_retries(url)
            if res["ok"]:
                return res["json"]
            return {"error": res.get("error")}
        except Exception as e:
            return {"error": str(e)}
    
    async def save_jupiter_extended_data(self, token_id: int, token_address: str, jupiter_data: Any) -> bool:
        """
        –ó–±–µ—Ä—ñ–≥–∞—î –î–û–î–ê–¢–ö–û–í–Ü –¥–∞–Ω—ñ Jupiter (stats, audit, firstPool, tags)
        
        –ù–µ —á—ñ–ø–∞—î –æ—Å–Ω–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é token_ids (—Ü–µ —Ä–æ–±–∏—Ç—å JupiterScannerV2).
        –¢—ñ–ª—å–∫–∏ –∑–∞–ø–æ–≤–Ω—é—î token_stats, token_audit, token_first_pool, token_tags.
        """
        try:
            if not isinstance(jupiter_data, list) or not jupiter_data:
                if self.debug:
                    print(f"‚ö†Ô∏è  Jupiter Search –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {token_address}")
                return False
            
            # Jupiter Search –ø–æ–≤–µ—Ä—Ç–∞—î –º–∞—Å–∏–≤, –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π —Ç–æ–∫–µ–Ω
            token_data = jupiter_data[0]
            
            if token_data.get('id') != token_address:
                if self.debug:
                    print(f"‚ö†Ô∏è  Jupiter –ø–æ–≤–µ—Ä–Ω—É–≤ —ñ–Ω—à–∏–π —Ç–æ–∫–µ–Ω: {token_data.get('id')} != {token_address}")
                return False
            
            pool = await get_db_pool()
            
            async with pool.acquire() as conn:
                # 1. Token Stats (5m, 1h, 6h, 24h)
                stats_5m = token_data.get('stats5m', {})
                stats_1h = token_data.get('stats1h', {})
                stats_6h = token_data.get('stats6h', {})
                stats_24h = token_data.get('stats24h', {})
                
                if stats_5m or stats_1h or stats_6h or stats_24h:
                    await conn.execute("""
                        INSERT INTO token_stats (
                            token_id,
                            stats_5m_price_change, stats_5m_buy_volume, stats_5m_sell_volume,
                            stats_5m_num_buys, stats_5m_num_sells, stats_5m_num_traders, stats_5m_num_net_buyers,
                            stats_1h_price_change, stats_1h_buy_volume, stats_1h_sell_volume,
                            stats_1h_num_buys, stats_1h_num_sells, stats_1h_num_traders, stats_1h_num_net_buyers,
                            stats_6h_price_change, stats_6h_buy_volume, stats_6h_sell_volume,
                            stats_6h_num_buys, stats_6h_num_sells, stats_6h_num_traders, stats_6h_num_net_buyers,
                            stats_24h_price_change, stats_24h_buy_volume, stats_24h_sell_volume,
                            stats_24h_num_buys, stats_24h_num_sells, stats_24h_num_traders, stats_24h_num_net_buyers
                        ) VALUES (
                            $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15,
                            $16, $17, $18, $19, $20, $21, $22, $23, $24, $25, $26, $27, $28, $29
                        )
                        ON CONFLICT (token_id) DO UPDATE SET
                            stats_5m_price_change = EXCLUDED.stats_5m_price_change,
                            stats_5m_buy_volume = EXCLUDED.stats_5m_buy_volume,
                            stats_5m_sell_volume = EXCLUDED.stats_5m_sell_volume,
                            stats_5m_num_buys = EXCLUDED.stats_5m_num_buys,
                            stats_5m_num_sells = EXCLUDED.stats_5m_num_sells,
                            stats_5m_num_traders = EXCLUDED.stats_5m_num_traders,
                            stats_5m_num_net_buyers = EXCLUDED.stats_5m_num_net_buyers,
                            stats_1h_price_change = EXCLUDED.stats_1h_price_change,
                            stats_1h_buy_volume = EXCLUDED.stats_1h_buy_volume,
                            stats_1h_sell_volume = EXCLUDED.stats_1h_sell_volume,
                            stats_1h_num_buys = EXCLUDED.stats_1h_num_buys,
                            stats_1h_num_sells = EXCLUDED.stats_1h_num_sells,
                            stats_1h_num_traders = EXCLUDED.stats_1h_num_traders,
                            stats_1h_num_net_buyers = EXCLUDED.stats_1h_num_net_buyers,
                            stats_6h_price_change = EXCLUDED.stats_6h_price_change,
                            stats_6h_buy_volume = EXCLUDED.stats_6h_buy_volume,
                            stats_6h_sell_volume = EXCLUDED.stats_6h_sell_volume,
                            stats_6h_num_buys = EXCLUDED.stats_6h_num_buys,
                            stats_6h_num_sells = EXCLUDED.stats_6h_num_sells,
                            stats_6h_num_traders = EXCLUDED.stats_6h_num_traders,
                            stats_6h_num_net_buyers = EXCLUDED.stats_6h_num_net_buyers,
                            stats_24h_price_change = EXCLUDED.stats_24h_price_change,
                            stats_24h_buy_volume = EXCLUDED.stats_24h_buy_volume,
                            stats_24h_sell_volume = EXCLUDED.stats_24h_sell_volume,
                            stats_24h_num_buys = EXCLUDED.stats_24h_num_buys,
                            stats_24h_num_sells = EXCLUDED.stats_24h_num_sells,
                            stats_24h_num_traders = EXCLUDED.stats_24h_num_traders,
                            stats_24h_num_net_buyers = EXCLUDED.stats_24h_num_net_buyers,
                            updated_at = CURRENT_TIMESTAMP
                    """,
                        token_id,
                        float(stats_5m.get('priceChange', 0)) if stats_5m.get('priceChange') else None,
                        float(stats_5m.get('buyVolume', 0)) if stats_5m.get('buyVolume') else None,
                        float(stats_5m.get('sellVolume', 0)) if stats_5m.get('sellVolume') else None,
                        stats_5m.get('numBuys', 0) if stats_5m.get('numBuys') else None,
                        stats_5m.get('numSells', 0) if stats_5m.get('numSells') else None,
                        stats_5m.get('numTraders', 0) if stats_5m.get('numTraders') else None,
                        stats_5m.get('numNetBuyers', 0) if stats_5m.get('numNetBuyers') else None,
                        float(stats_1h.get('priceChange', 0)) if stats_1h.get('priceChange') else None,
                        float(stats_1h.get('buyVolume', 0)) if stats_1h.get('buyVolume') else None,
                        float(stats_1h.get('sellVolume', 0)) if stats_1h.get('sellVolume') else None,
                        stats_1h.get('numBuys', 0) if stats_1h.get('numBuys') else None,
                        stats_1h.get('numSells', 0) if stats_1h.get('numSells') else None,
                        stats_1h.get('numTraders', 0) if stats_1h.get('numTraders') else None,
                        stats_1h.get('numNetBuyers', 0) if stats_1h.get('numNetBuyers') else None,
                        float(stats_6h.get('priceChange', 0)) if stats_6h.get('priceChange') else None,
                        float(stats_6h.get('buyVolume', 0)) if stats_6h.get('buyVolume') else None,
                        float(stats_6h.get('sellVolume', 0)) if stats_6h.get('sellVolume') else None,
                        stats_6h.get('numBuys', 0) if stats_6h.get('numBuys') else None,
                        stats_6h.get('numSells', 0) if stats_6h.get('numSells') else None,
                        stats_6h.get('numTraders', 0) if stats_6h.get('numTraders') else None,
                        stats_6h.get('numNetBuyers', 0) if stats_6h.get('numNetBuyers') else None,
                        float(stats_24h.get('priceChange', 0)) if stats_24h.get('priceChange') else None,
                        float(stats_24h.get('buyVolume', 0)) if stats_24h.get('buyVolume') else None,
                        float(stats_24h.get('sellVolume', 0)) if stats_24h.get('sellVolume') else None,
                        stats_24h.get('numBuys', 0) if stats_24h.get('numBuys') else None,
                        stats_24h.get('numSells', 0) if stats_24h.get('numSells') else None,
                        stats_24h.get('numTraders', 0) if stats_24h.get('numTraders') else None,
                        stats_24h.get('numNetBuyers', 0) if stats_24h.get('numNetBuyers') else None
                    )
                
                # 2. Token Audit
                audit = token_data.get('audit', {})
                if audit:
                    await conn.execute("""
                        INSERT INTO token_audit (
                            token_id, mint_authority_disabled, freeze_authority_disabled,
                            top_holders_percentage, dev_balance_percentage, dev_migrations
                        ) VALUES ($1, $2, $3, $4, $5, $6)
                        ON CONFLICT (token_id) DO UPDATE SET
                            mint_authority_disabled = EXCLUDED.mint_authority_disabled,
                            freeze_authority_disabled = EXCLUDED.freeze_authority_disabled,
                            top_holders_percentage = EXCLUDED.top_holders_percentage,
                            dev_balance_percentage = EXCLUDED.dev_balance_percentage,
                            dev_migrations = EXCLUDED.dev_migrations,
                            updated_at = CURRENT_TIMESTAMP
                    """,
                        token_id,
                        audit.get('mintAuthorityDisabled', False),
                        audit.get('freezeAuthorityDisabled', False),
                        float(audit.get('topHoldersPercentage', 0)) if audit.get('topHoldersPercentage') else None,
                        float(audit.get('devBalancePercentage', 0)) if audit.get('devBalancePercentage') else None,
                        audit.get('devMigrations', 0) if audit.get('devMigrations') else None
                    )
                
                # 3. Token First Pool
                first_pool = token_data.get('firstPool', {})
                if first_pool:
                    pool_created_at = first_pool.get('createdAt', '')
                    if pool_created_at:
                        pool_created_dt = datetime.fromisoformat(pool_created_at.replace('Z', '+00:00')).replace(tzinfo=None)
                    else:
                        pool_created_dt = None
                    
                    await conn.execute("""
                        INSERT INTO token_first_pool (token_id, pool_id, created_at)
                        VALUES ($1, $2, $3)
                        ON CONFLICT (token_id) DO UPDATE SET
                            pool_id = EXCLUDED.pool_id,
                            created_at = EXCLUDED.created_at,
                            updated_at = CURRENT_TIMESTAMP
                    """,
                        token_id,
                        first_pool.get('id', ''),
                        pool_created_dt
                    )
                
                # 4. Token Tags
                tags = token_data.get('tags', [])
                if tags:
                    # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ —Ç–µ–≥–∏
                    await conn.execute("DELETE FROM token_tags WHERE token_id = $1", token_id)
                    
                    # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ —Ç–µ–≥–∏
                    for tag in tags:
                        if tag and tag.strip():
                            await conn.execute("""
                                INSERT INTO token_tags (token_id, tag)
                                VALUES ($1, $2)
                                ON CONFLICT (token_id, tag) DO NOTHING
                            """, token_id, tag.strip())
                
                # –û–Ω–æ–≤–ª—é—î–º–æ check_jupiter counter
                await conn.execute("""
                    UPDATE token_ids 
                    SET check_jupiter = LEAST(check_jupiter + 1, 3)
                    WHERE id = $1
                """, token_id)
                
                if self.debug:
                    print(f"‚úÖ Saved Jupiter extended data for token_id={token_id}, address={token_address}")
                
                return True
                
        except Exception as e:
            if self.debug:
                print(f"‚ùå Error saving Jupiter extended data for {token_address}: {e}")
            return False
    
    async def get_tokens_to_scan(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        –û—Ç—Ä–∏–º—É—î –†–Ü–í–ù–û 100 —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è BATCH –æ–Ω–æ–≤–ª–µ–Ω–Ω—è Jupiter –¥–∞–Ω–∏—Ö
        
        –õ–æ–≥—ñ–∫–∞ (CURSOR-BASED):
        1. –ü–æ—á–∏–Ω–∞—î–º–æ –∑ self.last_processed_id (–¥–µ –∑—É–ø–∏–Ω–∏–ª–∏—Å—å –º–∏–Ω—É–ª–æ–≥–æ —Ä–∞–∑—É)
        2. –Ü—Ç–µ—Ä—É—î–º–æ—Å—è –ø–æ –í–°–Ü–• —Ç–æ–∫–µ–Ω–∞—Ö (ORDER BY id ASC)
        3. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç–æ–∫–µ–Ω–∏ –¥–µ check_jupiter >= 3
        4. –ó–±–∏—Ä–∞—î–º–æ –†–Ü–í–ù–û 100 —Ç–æ–∫–µ–Ω—ñ–≤ (–Ω–µ –±—ñ–ª—å—à–µ, –Ω–µ –º–µ–Ω—à–µ)
        5. –ó–±–µ—Ä—ñ–≥–∞—î–º–æ ID –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤ self.last_processed_id
        6. –Ø–∫—â–æ –¥—ñ–π—à–ª–∏ –¥–æ –∫—ñ–Ω—Ü—è –ë–î ‚Üí —Å–∫–∏–¥–∞—î–º–æ cursor –Ω–∞ 0 (–ø–æ—á–∏–Ω–∞—î–º–æ —Å–ø–æ—á–∞—Ç–∫—É)
        
        –ü—Ä–∏–∫–ª–∞–¥ (254 —Ç–æ–∫–µ–Ω–∏):
        –¶–∏–∫–ª 1: Token 1-150 ‚Üí –∑–Ω–∞–π—à–ª–∏ 100 –∑ check<3 ‚Üí last_id=150
        –¶–∏–∫–ª 2: Token 151-200 ‚Üí –∑–Ω–∞–π—à–ª–∏ 50 –∑ check<3 ‚Üí –ø—Ä–æ–¥–æ–≤–∂—É—î–º–æ
                Token 201-254 ‚Üí –∑–Ω–∞–π—à–ª–∏ —â–µ 50 ‚Üí –≤—Å—å–æ–≥–æ 100 ‚Üí last_id=254
        –¶–∏–∫–ª 3: –î—ñ–π—à–ª–∏ –¥–æ –∫—ñ–Ω—Ü—è (254) ‚Üí RESET cursor=0 ‚Üí –ø–æ—á–∏–Ω–∞—î–º–æ –∑ Token 1
        
        Returns:
            List[Dict]: –†–Ü–í–ù–û 100 —Ç–æ–∫–µ–Ω—ñ–≤ (–∞–±–æ –º–µ–Ω—à–µ, —è–∫—â–æ –≤ –ë–î < 100 –∑ check<3)
        """
        try:
            pool = await get_db_pool()
            tokens = []
            
            async with pool.acquire() as conn:
                # –û—Ç—Ä–∏–º—É—î–º–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π ID –≤ –ë–î
                max_id = await conn.fetchval("SELECT MAX(id) FROM token_ids")
                if not max_id:
                    return []
                
                # –Ø–∫—â–æ –∫—É—Ä—Å–æ—Ä –≤–∏–π—à–æ–≤ –∑–∞ –º–µ–∂—ñ - —Å–∫–∏–¥–∞—î–º–æ –Ω–∞ 0
                if self.last_processed_id >= max_id:
                    self.last_processed_id = 0
                    if self.debug:
                        print(f"üîÑ Cursor RESET: –ø–æ—á–∏–Ω–∞—î–º–æ –∑ –ø–æ—á–∞—Ç–∫—É –ë–î")
                
                current_id = self.last_processed_id
                
                # –ó–±–∏—Ä–∞—î–º–æ –†–Ü–í–ù–û 100 —Ç–æ–∫–µ–Ω—ñ–≤ (–∞–±–æ –º–µ–Ω—à–µ —è–∫—â–æ –∑–∞–∫—ñ–Ω—á–∏–ª–∏—Å—å)
                while len(tokens) < limit:
                    # Fetch –Ω–∞—Å—Ç—É–ø–Ω—É –ø–æ—Ä—Ü—ñ—é —Ç–æ–∫–µ–Ω—ñ–≤ (–ø–æ 200 –∑–∞ —Ä–∞–∑ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ)
                    rows = await conn.fetch("""
                        SELECT id, token_address, check_jupiter
                        FROM token_ids
                        WHERE id > $1 AND check_jupiter < 3
                        ORDER BY id ASC
                        LIMIT 200
                    """, current_id)
                    
                    if not rows:
                        # –î—ñ–π—à–ª–∏ –¥–æ –∫—ñ–Ω—Ü—è –ë–î - –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î —â–µ —Ç–æ–∫–µ–Ω–∏ –∑ –ø–æ—á–∞—Ç–∫—É
                        if current_id > 0:
                            if self.debug:
                                print(f"üìç –î–æ—Å—è–≥–ª–∏ –∫—ñ–Ω—Ü—è –ë–î (id={current_id}), –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∑ –ø–æ—á–∞—Ç–∫—É...")
                            # –°–ø—Ä–æ–±—É—î–º–æ –∑ –ø–æ—á–∞—Ç–∫—É –ë–î
                            rows = await conn.fetch("""
                                SELECT id, token_address, check_jupiter
                                FROM token_ids
                                WHERE id <= $1 AND check_jupiter < 3
                                ORDER BY id ASC
                                LIMIT 200
                            """, self.last_processed_id)
                            
                            if not rows:
                                # –ù–µ–º–∞—î –±—ñ–ª—å—à–µ —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
                                break
                            else:
                                # Reset cursor –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ü–∏–∫–ª—É
                                current_id = 0
                        else:
                            # –í–∂–µ –ø—Ä–æ–±—É–≤–∞–ª–∏ –∑ –ø–æ—á–∞—Ç–∫—É - –Ω–µ–º–∞—î –±—ñ–ª—å—à–µ —Ç–æ–∫–µ–Ω—ñ–≤
                            break
                    
                    # –î–æ–¥–∞—î–º–æ —Ç–æ–∫–µ–Ω–∏ –¥–æ —Å–ø–∏—Å–∫—É
                    for row in rows:
                        if len(tokens) >= limit:
                            break
                        tokens.append({
                            "token_id": row['id'],
                            "token_address": row['token_address'],
                            "check_jupiter": row['check_jupiter']
                        })
                        current_id = row['id']  # –û–Ω–æ–≤–ª—é—î–º–æ –ø–æ–∑–∏—Ü—ñ—é –∫—É—Ä—Å–æ—Ä–∞
                    
                    # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —Ç–æ–∫–µ–Ω—ñ–≤ - –≤–∏—Ö–æ–¥–∏–º–æ
                    if len(rows) < 200 and len(tokens) < limit:
                        break
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–∑–∏—Ü—ñ—é –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ü–∏–∫–ª—É
                if tokens:
                    self.last_processed_id = tokens[-1]["token_id"]
                    if self.debug:
                        print(f"üìç Cursor position: last_id={self.last_processed_id}, collected={len(tokens)} tokens")
                
                return tokens
                
        except Exception as e:
            if self.debug:
                print(f"‚ùå Error getting tokens to scan: {e}")
            return []
    
    async def scan_token(self, token: Dict[str, Any]) -> bool:
        """–°–∫–∞–Ω—É—î –æ–¥–∏–Ω —Ç–æ–∫–µ–Ω"""
        try:
            token_id = token["token_id"]
            token_address = token["token_address"]
            
            if self.debug:
                print(f"üîç Scanning token_id={token_id}, address={token_address}, check={token['check_jupiter']}")
            
            jupiter_data = await self.get_token_data(token_address)
            
            # API error ‚Üí increment check_jupiter
            if "error" in jupiter_data:
                if self.debug:
                    print(f"‚ö†Ô∏è  Jupiter API error for {token_address}: {jupiter_data['error']}")
                pool = await get_db_pool()
                async with pool.acquire() as conn:
                    await conn.execute("""
                        UPDATE token_ids 
                        SET check_jupiter = LEAST(check_jupiter + 1, 3)
                        WHERE id = $1
                    """, token_id)
                return False
            
            # Try to save data (increments check_jupiter inside)
            success = await self.save_jupiter_extended_data(token_id, token_address, jupiter_data)
            
            # If save failed (no data) ‚Üí ALSO increment check_jupiter
            if not success:
                pool = await get_db_pool()
                async with pool.acquire() as conn:
                    await conn.execute("""
                        UPDATE token_ids 
                        SET check_jupiter = LEAST(check_jupiter + 1, 3)
                        WHERE id = $1
                    """, token_id)
            
            return success
            
        except Exception as e:
            if self.debug:
                print(f"‚ùå Error scanning token {token.get('token_address')}: {e}")
            # On exception ‚Üí also increment to avoid infinite loop
            try:
                pool = await get_db_pool()
                async with pool.acquire() as conn:
                    await conn.execute("""
                        UPDATE token_ids 
                        SET check_jupiter = LEAST(check_jupiter + 1, 3)
                        WHERE id = $1
                    """, token["token_id"])
            except:
                pass
            return False
    
    async def _auto_scan_loop(self):
        """
        Auto-scan loop –¥–ª—è BATCH –æ–Ω–æ–≤–ª–µ–Ω–Ω—è Jupiter –¥–∞–Ω–∏—Ö
        
        –õ–æ–≥—ñ–∫–∞:
        1. –ö–æ–∂–Ω—ñ 3 —Å–µ–∫—É–Ω–¥–∏ –±–µ—Ä–µ–º–æ 100 —Ç–æ–∫–µ–Ω—ñ–≤ –¥–µ check_jupiter < 3
        2. –†–æ–±–∏–º–æ –û–î–ò–ù batch –∑–∞–ø–∏—Ç –¥–æ Jupiter API (comma-separated addresses)
        3. –û–Ω–æ–≤–ª—é—î–º–æ –¥–∞–Ω—ñ + —ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç—É—î–º–æ check_jupiter –¥–ª—è –í–°–Ü–• —Ç–æ–∫–µ–Ω—ñ–≤
        4. –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ - –∑–Ω–æ–≤—É –ø–µ—Ä—à—ñ 100 —Ç–æ–∫–µ–Ω—ñ–≤ (ORDER BY created_at ASC)
        5. –¶–∏–∫–ª –±–µ–∑–∫—ñ–Ω–µ—á–Ω–∏–π
        """
        while self.is_scanning:
            try:
                # –ö—Ä–æ–∫ 1: –ë–µ—Ä–µ–º–æ 100 —Ç–æ–∫–µ–Ω—ñ–≤ (–Ω–∞–π—Å—Ç–∞—Ä—ñ—à—ñ –∑ check_jupiter < 3)
                tokens = await self.get_tokens_to_scan(limit=self.batch_size)
                
                if not tokens:
                    if self.debug:
                        print(f"‚ÑπÔ∏è  –ù–µ–º–∞—î —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è (–≤—Å—ñ check_jupiter >= 3)")
                    await asyncio.sleep(self.scan_interval)
                    continue
                
                if self.debug:
                    print(f"\n{'='*80}")
                    print(f"üìä BATCH SCAN: {len(tokens)} —Ç–æ–∫–µ–Ω—ñ–≤")
                    print(f"{'='*80}")
                
                # –ö—Ä–æ–∫ 2: –û–¥–∏–Ω batch –∑–∞–ø–∏—Ç –¥–ª—è –≤—Å—ñ—Ö —Ç–æ–∫–µ–Ω—ñ–≤
                token_addresses = [t["token_address"] for t in tokens]
                token_map = {t["token_address"]: t for t in tokens}  # address -> token_id mapping
                
                jupiter_data = await self.get_tokens_data_batch(token_addresses)
                
                # –ö—Ä–æ–∫ 3: –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                if "error" in jupiter_data:
                    if self.debug:
                        print(f"‚ö†Ô∏è  Jupiter API error: {jupiter_data['error']}")
                    # –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç—É—î–º–æ check_jupiter –¥–ª—è –í–°–Ü–• —Ç–æ–∫–µ–Ω—ñ–≤ –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
                    await self._increment_check_jupiter_bulk(tokens)
                    await asyncio.sleep(self.scan_interval)
                    continue
                
                # Jupiter –ø–æ–≤–µ—Ä—Ç–∞—î –º–∞—Å–∏–≤ —Ç–æ–∫–µ–Ω—ñ–≤
                if not isinstance(jupiter_data, list):
                    if self.debug:
                        print(f"‚ö†Ô∏è  Jupiter –ø–æ–≤–µ—Ä–Ω—É–≤ –Ω–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–∏—Ö")
                    await self._increment_check_jupiter_bulk(tokens)
                    await asyncio.sleep(self.scan_interval)
                    continue
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω —Ç–æ–∫–µ–Ω –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                updated_count = 0
                for token_data in jupiter_data:
                    token_address = token_data.get('id')
                    if token_address and token_address in token_map:
                        token_info = token_map[token_address]
                        success = await self.save_jupiter_extended_data(
                            token_info["token_id"],
                            token_address,
                            [token_data]  # save_jupiter_extended_data –æ—á—ñ–∫—É—î –º–∞—Å–∏–≤
                        )
                        if success:
                            updated_count += 1
                
                # –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç—É—î–º–æ check_jupiter –¥–ª—è –í–°–Ü–• —Ç–æ–∫–µ–Ω—ñ–≤ (–Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –¥–∞–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ)
                await self._increment_check_jupiter_bulk(tokens)
                
                if self.debug:
                    print(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ {updated_count}/{len(tokens)} —Ç–æ–∫–µ–Ω—ñ–≤")
                    print(f"‚è≥ –ó–∞—Ç—Ä–∏–º–∫–∞ {self.scan_interval}s –ø–µ—Ä–µ–¥ –Ω–∞—Å—Ç—É–ø–Ω–∏–º –±–∞—Ç—á–µ–º...")
                    print(f"{'='*80}\n")
                
            except Exception as e:
                if self.debug:
                    print(f"‚ùå Auto-scan loop error: {e}")
            
            await asyncio.sleep(self.scan_interval)
    
    async def _increment_check_jupiter_bulk(self, tokens: List[Dict[str, Any]]):
        """–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç—É—î check_jupiter –¥–ª—è –≤—Å—ñ—Ö —Ç–æ–∫–µ–Ω—ñ–≤ –≤ –±–∞—Ç—á—ñ"""
        try:
            pool = await get_db_pool()
            token_ids = [t["token_id"] for t in tokens]
            
            async with pool.acquire() as conn:
                await conn.execute("""
                    UPDATE token_ids 
                    SET check_jupiter = LEAST(check_jupiter + 1, 3)
                    WHERE id = ANY($1::int[])
                """, token_ids)
                
                if self.debug:
                    print(f"üìä –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–æ–≤–∞–Ω–æ check_jupiter –¥–ª—è {len(token_ids)} —Ç–æ–∫–µ–Ω—ñ–≤")
                    
        except Exception as e:
            if self.debug:
                print(f"‚ùå Error incrementing check_jupiter: {e}")
    
    async def start_auto_scan(self):
        """–ó–∞–ø—É—Å–∫–∞—î auto-scan"""
        if self.is_scanning:
            return {"success": False, "message": "Jupiter analyzer already running"}
        
        self.is_scanning = True
        self.scan_task = asyncio.create_task(self._auto_scan_loop())
        return {"success": True, "message": "Jupiter analyzer started"}
    
    async def stop_auto_scan(self):
        """–ó—É–ø–∏–Ω—è—î auto-scan"""
        if not self.is_scanning:
            return {"success": False, "message": "Jupiter analyzer not running"}
        
        self.is_scanning = False
        if self.scan_task:
            self.scan_task.cancel()
            try:
                await self.scan_task
            except asyncio.CancelledError:
                pass
            self.scan_task = None
        
        return {"success": True, "message": "Jupiter analyzer stopped"}
    
    def get_status(self):
        """–°—Ç–∞—Ç—É—Å analyzer"""
        return {
            "is_scanning": self.is_scanning,
            "scan_interval": self.scan_interval,
            "batch_size": self.batch_size
        }


# Singleton instance
jupiter_analyzer_instance: Optional[JupiterAnalyzer] = None

async def get_jupiter_analyzer() -> JupiterAnalyzer:
    global jupiter_analyzer_instance
    if jupiter_analyzer_instance is None:
        jupiter_analyzer_instance = JupiterAnalyzer(debug=True)
        await jupiter_analyzer_instance.ensure_connection()
        await jupiter_analyzer_instance.ensure_session()
    return jupiter_analyzer_instance


async def refresh_missing_jupiter_data(debug: bool = True, delay_seconds: float = 1.0, batch_size: int = 5, max_tokens: int = None, force_rescan: bool = False) -> Dict:
    """
    –†—É—á–Ω–µ –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è Jupiter –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö (stats, audit, firstPool, tags)
    
    –ü—Ä–æ—Ö–æ–¥–∏—Ç—å –ø–æ –≤—Å—ñ—Ö —Ç–æ–∫–µ–Ω–∞—Ö –ë–ï–ó token_stats —ñ –∑–∞–ø–∏—Ç—É—î Jupiter Search API.
    Rate limit: 5 –∑–∞–ø–∏—Ç—ñ–≤/—Å–µ–∫—É–Ω–¥—É (batch_size=5, delay=1.0s)
    
    Args:
        debug: –í–∏–≤–æ–¥–∏—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—ñ –ª–æ–≥–∏
        delay_seconds: –ó–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ –±–∞—Ç—á–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º 1.0s)
        batch_size: –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤ –Ω–∞ –±–∞—Ç—á (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º 5)
        max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ (None = –≤—Å—ñ —Ç–æ–∫–µ–Ω–∏)
        force_rescan: –Ø–∫—â–æ True, —Å–∫–∞–Ω—É—î –Ω–∞–≤—ñ—Ç—å —Ç–æ–∫–µ–Ω–∏ –¥–µ check_jupiter >= 3
    
    Returns:
        Dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: total_tokens, processed_tokens, success_count, failed_count
    
    Usage:
        # –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –¥–ª—è –≤—Å—ñ—Ö —Ç–æ–∫–µ–Ω—ñ–≤ –ë–ï–ó stats:
        python3 -c "import asyncio; from _v2_analyzer_jupiter import refresh_missing_jupiter_data; asyncio.run(refresh_missing_jupiter_data())"
        
        # –ü–µ—Ä—à—ñ 10 —Ç–æ–∫–µ–Ω—ñ–≤ (—Ç–µ—Å—Ç):
        python3 -c "import asyncio; from _v2_analyzer_jupiter import refresh_missing_jupiter_data; asyncio.run(refresh_missing_jupiter_data(max_tokens=10))"
    """
    analyzer = JupiterAnalyzer(debug=debug)
    
    try:
        await analyzer.ensure_connection()
        await analyzer.ensure_session()
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–æ–∫–µ–Ω–∏ –ë–ï–ó token_stats
        pool = await get_db_pool()
        async with pool.acquire() as conn:
            if force_rescan:
                rows = await conn.fetch("""
                    SELECT t.id, t.token_address, t.check_jupiter
                    FROM token_ids t
                    LEFT JOIN token_stats s ON t.id = s.token_id
                    WHERE s.token_id IS NULL
                    ORDER BY t.created_at ASC
                """)
            else:
                rows = await conn.fetch("""
                    SELECT t.id, t.token_address, t.check_jupiter
                    FROM token_ids t
                    LEFT JOIN token_stats s ON t.id = s.token_id
                    WHERE s.token_id IS NULL
                      AND t.check_jupiter < 3
                    ORDER BY t.created_at ASC
                """)
        
        tokens = [
            {
                "token_id": row['id'],
                "token_address": row['token_address'],
                "check_jupiter": row['check_jupiter']
            }
            for row in rows
        ]
        
        if not tokens:
            print("‚ö†Ô∏è  –¢–æ–∫–µ–Ω—ñ–≤ –ë–ï–ó Jupiter –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –ë–î")
            return {
                "success": True,
                "total_tokens": 0,
                "processed_tokens": 0,
                "success_count": 0,
                "failed_count": 0
            }
        
        if max_tokens:
            tokens = tokens[:max_tokens]
        
        print(f"\n{'='*80}")
        print(f"üöÄ –ó–ê–ü–û–í–ù–ï–ù–ù–Ø JUPITER –î–û–î–ê–¢–ö–û–í–ò–• –î–ê–ù–ò–• (stats, audit, firstPool, tags)")
        print(f"{'='*80}")
        print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–æ–∫–µ–Ω—ñ–≤ –ë–ï–ó stats: {len(tokens)}")
        if not force_rescan:
            print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç–æ–∫–µ–Ω–∏ –∑ check_jupiter >= 3")
        else:
            print(f"üîÑ Force rescan: —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è –í–°–Ü–• —Ç–æ–∫–µ–Ω—ñ–≤ –ë–ï–ó stats")
        print(f"‚è±Ô∏è  –ó–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ –±–∞—Ç—á–∞–º–∏: {delay_seconds}s")
        print(f"üì¶ –†–æ–∑–º—ñ—Ä –±–∞—Ç—á—É: {batch_size} —Ç–æ–∫–µ–Ω—ñ–≤/—Å–µ–∫")
        if max_tokens:
            print(f"üß™ –¢–ï–°–¢–û–í–ò–ô –†–ï–ñ–ò–ú: –æ–±—Ä–æ–±–ª—é—î–º–æ —Ç—ñ–ª—å–∫–∏ {max_tokens} —Ç–æ–∫–µ–Ω–∏")
        print(f"{'='*80}\n")
        
        success_count = 0
        failed_count = 0
        processed_tokens = 0
        
        total_batches = (len(tokens) + batch_size - 1) // batch_size
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(tokens))
            batch = tokens[start_idx:end_idx]
            
            print(f"\n{'‚îÄ'*80}")
            print(f"üì¶ –ë–∞—Ç—á {batch_idx + 1}/{total_batches} ({len(batch)} —Ç–æ–∫–µ–Ω—ñ–≤)")
            print(f"{'‚îÄ'*80}")
            
            tasks = []
            for token in batch:
                tasks.append(analyzer.scan_token(token))
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for idx, result in enumerate(results):
                token = batch[idx]
                processed_tokens += 1
                
                if isinstance(result, Exception):
                    failed_count += 1
                    if debug:
                        print(f"‚ùå Token {token['token_address'][:16]}... failed: {result}")
                elif result is True:
                    success_count += 1
                    if debug:
                        print(f"‚úÖ Token {token['token_address'][:16]}... success")
                else:
                    failed_count += 1
                    if debug:
                        print(f"‚ö†Ô∏è  Token {token['token_address'][:16]}... no data found")
            
            print(f"üìä –ë–∞—Ç—á —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {sum(1 for r in results if r is True)}/{len(batch)} —É—Å–ø—ñ—à–Ω–æ")
            
            if batch_idx < total_batches - 1:
                print(f"‚è≥ –ó–∞—Ç—Ä–∏–º–∫–∞ {delay_seconds}s –ø–µ—Ä–µ–¥ –Ω–∞—Å—Ç—É–ø–Ω–∏–º –±–∞—Ç—á–µ–º...")
                await asyncio.sleep(delay_seconds)
        
        print(f"\n{'='*80}")
        print(f"üéâ –ó–ê–ü–û–í–ù–ï–ù–ù–Ø –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"{'='*80}")
        print(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ —Ç–æ–∫–µ–Ω—ñ–≤: {processed_tokens}/{len(tokens)}")
        print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ –∑–∞–ø–æ–≤–Ω–µ–Ω–æ: {success_count}")
        print(f"‚ùå –ü–æ–º–∏–ª–æ–∫/–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {failed_count}")
        print(f"{'='*80}\n")
        
        return {
            "success": True,
            "total_tokens": len(tokens),
            "processed_tokens": processed_tokens,
            "success_count": success_count,
            "failed_count": failed_count
        }
        
    finally:
        await analyzer.close()

